{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보스턴 주택 가격 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "    path='boston_housing.npz',\n",
    "    test_split=0.2,\n",
    "    seed=777\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 형태 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (404,)\n",
      "(102, 13) (102,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리 및 검증 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 데이터 표준화\n",
    "mean = np.mean(x_train, axis = 0)\n",
    "std = np.std(x_train, axis = 0)\n",
    "\n",
    "x_train = (x_train - mean) / std\n",
    "x_test = (x_test - mean) / std\n",
    "\n",
    "# 검증 데이터셋을 만듭니다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.33, random_state = 777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "# 입력 데이터의 형태를 꼭 명시해야 합니다.\n",
    "# 13차원의 데이터를 입력으로 받고, 64개의 출력을 가지는 첫 번째 Dense 층\n",
    "model.add(Dense(64, activation = 'relu', input_shape = (13, )))\n",
    "model.add(Dense(32, activation = 'relu')) # 32개의 출력을 가지는 Dense 층\n",
    "model.add(Dense(1)) # 하나의 값을 출력합니다.\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습하고 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 134 samples\n",
      "Epoch 1/300\n",
      "270/270 [==============================] - 0s 247us/sample - loss: 4.5889 - mae: 1.5195 - val_loss: 10.9384 - val_mae: 2.3607\n",
      "Epoch 2/300\n",
      "270/270 [==============================] - 0s 214us/sample - loss: 4.5764 - mae: 1.5050 - val_loss: 11.6520 - val_mae: 2.4621\n",
      "Epoch 3/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 4.5693 - mae: 1.5290 - val_loss: 11.1255 - val_mae: 2.3964\n",
      "Epoch 4/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 4.6092 - mae: 1.5161 - val_loss: 11.1534 - val_mae: 2.3856\n",
      "Epoch 5/300\n",
      "270/270 [==============================] - 0s 207us/sample - loss: 4.5157 - mae: 1.5147 - val_loss: 11.7122 - val_mae: 2.4671\n",
      "Epoch 6/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 4.5470 - mae: 1.5264 - val_loss: 11.1191 - val_mae: 2.3859\n",
      "Epoch 7/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 4.5315 - mae: 1.5036 - val_loss: 11.1705 - val_mae: 2.3902\n",
      "Epoch 8/300\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 4.4647 - mae: 1.4941 - val_loss: 11.4265 - val_mae: 2.4322\n",
      "Epoch 9/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 4.5504 - mae: 1.5258 - val_loss: 11.2071 - val_mae: 2.3998\n",
      "Epoch 10/300\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 4.4792 - mae: 1.4939 - val_loss: 11.2039 - val_mae: 2.3963\n",
      "Epoch 11/300\n",
      "270/270 [==============================] - 0s 225us/sample - loss: 4.5047 - mae: 1.5214 - val_loss: 11.4873 - val_mae: 2.4425\n",
      "Epoch 12/300\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 4.4372 - mae: 1.5063 - val_loss: 10.9880 - val_mae: 2.3666\n",
      "Epoch 13/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 4.4943 - mae: 1.4902 - val_loss: 11.1535 - val_mae: 2.3959\n",
      "Epoch 14/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 4.4751 - mae: 1.5002 - val_loss: 11.4678 - val_mae: 2.4323\n",
      "Epoch 15/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 4.4079 - mae: 1.4917 - val_loss: 11.1094 - val_mae: 2.3889\n",
      "Epoch 16/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 4.4065 - mae: 1.4775 - val_loss: 11.4295 - val_mae: 2.4158\n",
      "Epoch 17/300\n",
      "270/270 [==============================] - 0s 236us/sample - loss: 4.3973 - mae: 1.4826 - val_loss: 11.4941 - val_mae: 2.4305\n",
      "Epoch 18/300\n",
      "270/270 [==============================] - 0s 203us/sample - loss: 4.4136 - mae: 1.4905 - val_loss: 11.2445 - val_mae: 2.3757\n",
      "Epoch 19/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 4.3561 - mae: 1.4721 - val_loss: 11.3934 - val_mae: 2.4085\n",
      "Epoch 20/300\n",
      "270/270 [==============================] - 0s 211us/sample - loss: 4.3789 - mae: 1.4806 - val_loss: 11.3475 - val_mae: 2.4079\n",
      "Epoch 21/300\n",
      "270/270 [==============================] - 0s 233us/sample - loss: 4.3324 - mae: 1.4673 - val_loss: 11.2166 - val_mae: 2.3858\n",
      "Epoch 22/300\n",
      "270/270 [==============================] - 0s 218us/sample - loss: 4.4005 - mae: 1.4786 - val_loss: 11.4021 - val_mae: 2.4137\n",
      "Epoch 23/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 4.3179 - mae: 1.4704 - val_loss: 11.8498 - val_mae: 2.4559\n",
      "Epoch 24/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 4.3053 - mae: 1.4718 - val_loss: 11.3936 - val_mae: 2.4126\n",
      "Epoch 25/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 4.3003 - mae: 1.4739 - val_loss: 11.3443 - val_mae: 2.4126\n",
      "Epoch 26/300\n",
      "270/270 [==============================] - 0s 270us/sample - loss: 4.3145 - mae: 1.4526 - val_loss: 11.4053 - val_mae: 2.4118\n",
      "Epoch 27/300\n",
      "270/270 [==============================] - 0s 199us/sample - loss: 4.2735 - mae: 1.4504 - val_loss: 11.0979 - val_mae: 2.3921\n",
      "Epoch 28/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 4.2866 - mae: 1.4762 - val_loss: 11.3346 - val_mae: 2.3991\n",
      "Epoch 29/300\n",
      "270/270 [==============================] - 0s 225us/sample - loss: 4.2950 - mae: 1.4642 - val_loss: 11.0940 - val_mae: 2.3695\n",
      "Epoch 30/300\n",
      "270/270 [==============================] - 0s 199us/sample - loss: 4.2961 - mae: 1.4747 - val_loss: 11.4412 - val_mae: 2.4234\n",
      "Epoch 31/300\n",
      "270/270 [==============================] - 0s 222us/sample - loss: 4.2017 - mae: 1.4672 - val_loss: 11.5950 - val_mae: 2.4316\n",
      "Epoch 32/300\n",
      "270/270 [==============================] - 0s 203us/sample - loss: 4.1711 - mae: 1.4462 - val_loss: 11.4890 - val_mae: 2.4078\n",
      "Epoch 33/300\n",
      "270/270 [==============================] - 0s 214us/sample - loss: 4.2341 - mae: 1.4409 - val_loss: 11.5980 - val_mae: 2.4332\n",
      "Epoch 34/300\n",
      "270/270 [==============================] - 0s 211us/sample - loss: 4.1963 - mae: 1.4755 - val_loss: 11.2265 - val_mae: 2.3960\n",
      "Epoch 35/300\n",
      "270/270 [==============================] - 0s 229us/sample - loss: 4.1898 - mae: 1.4472 - val_loss: 11.2215 - val_mae: 2.3872\n",
      "Epoch 36/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 4.1433 - mae: 1.4397 - val_loss: 11.5141 - val_mae: 2.4199\n",
      "Epoch 37/300\n",
      "270/270 [==============================] - 0s 244us/sample - loss: 4.1325 - mae: 1.4456 - val_loss: 11.4119 - val_mae: 2.4079\n",
      "Epoch 38/300\n",
      "270/270 [==============================] - 0s 266us/sample - loss: 4.1631 - mae: 1.4532 - val_loss: 11.7794 - val_mae: 2.4474\n",
      "Epoch 39/300\n",
      "270/270 [==============================] - 0s 207us/sample - loss: 4.0568 - mae: 1.4250 - val_loss: 11.1380 - val_mae: 2.3809\n",
      "Epoch 40/300\n",
      "270/270 [==============================] - 0s 203us/sample - loss: 4.1297 - mae: 1.4422 - val_loss: 11.2117 - val_mae: 2.3837\n",
      "Epoch 41/300\n",
      "270/270 [==============================] - 0s 240us/sample - loss: 4.1067 - mae: 1.4195 - val_loss: 11.1559 - val_mae: 2.3685\n",
      "Epoch 42/300\n",
      "270/270 [==============================] - 0s 233us/sample - loss: 4.0953 - mae: 1.4197 - val_loss: 11.7888 - val_mae: 2.4448\n",
      "Epoch 43/300\n",
      "270/270 [==============================] - 0s 207us/sample - loss: 4.0986 - mae: 1.4390 - val_loss: 11.5750 - val_mae: 2.4116\n",
      "Epoch 44/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 4.0639 - mae: 1.4280 - val_loss: 11.4299 - val_mae: 2.3972\n",
      "Epoch 45/300\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 4.0849 - mae: 1.4152 - val_loss: 11.7497 - val_mae: 2.4359\n",
      "Epoch 46/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 4.0269 - mae: 1.4303 - val_loss: 11.8292 - val_mae: 2.4485\n",
      "Epoch 47/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 4.0917 - mae: 1.4264 - val_loss: 11.3154 - val_mae: 2.3793\n",
      "Epoch 48/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 3.9827 - mae: 1.4124 - val_loss: 11.8153 - val_mae: 2.4418\n",
      "Epoch 49/300\n",
      "270/270 [==============================] - 0s 218us/sample - loss: 4.1013 - mae: 1.4406 - val_loss: 11.5795 - val_mae: 2.4119\n",
      "Epoch 50/300\n",
      "270/270 [==============================] - 0s 199us/sample - loss: 3.9492 - mae: 1.3972 - val_loss: 11.2299 - val_mae: 2.3935\n",
      "Epoch 51/300\n",
      "270/270 [==============================] - 0s 222us/sample - loss: 4.0123 - mae: 1.4268 - val_loss: 11.6116 - val_mae: 2.4214\n",
      "Epoch 52/300\n",
      "270/270 [==============================] - 0s 214us/sample - loss: 3.9693 - mae: 1.4166 - val_loss: 11.3094 - val_mae: 2.3719\n",
      "Epoch 53/300\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 3.9701 - mae: 1.3986 - val_loss: 11.4888 - val_mae: 2.4054\n",
      "Epoch 54/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 4.0550 - mae: 1.4170 - val_loss: 11.6144 - val_mae: 2.4127\n",
      "Epoch 55/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 3.9356 - mae: 1.3978 - val_loss: 11.7215 - val_mae: 2.4219\n",
      "Epoch 56/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 3.9041 - mae: 1.3944 - val_loss: 11.4375 - val_mae: 2.4006\n",
      "Epoch 57/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 3.9730 - mae: 1.4378 - val_loss: 11.2539 - val_mae: 2.3835\n",
      "Epoch 58/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 3.9527 - mae: 1.4000 - val_loss: 11.3498 - val_mae: 2.3692\n",
      "Epoch 59/300\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 3.8600 - mae: 1.3965 - val_loss: 11.5266 - val_mae: 2.4136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/300\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 3.8709 - mae: 1.4098 - val_loss: 11.4581 - val_mae: 2.3934\n",
      "Epoch 61/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 3.8561 - mae: 1.4006 - val_loss: 11.3626 - val_mae: 2.3854\n",
      "Epoch 62/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 3.8375 - mae: 1.3759 - val_loss: 11.6720 - val_mae: 2.4180\n",
      "Epoch 63/300\n",
      "270/270 [==============================] - 0s 177us/sample - loss: 3.8636 - mae: 1.3868 - val_loss: 11.3509 - val_mae: 2.3904\n",
      "Epoch 64/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 3.8454 - mae: 1.3964 - val_loss: 11.7565 - val_mae: 2.4269\n",
      "Epoch 65/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 3.7693 - mae: 1.3706 - val_loss: 11.3971 - val_mae: 2.3970\n",
      "Epoch 66/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 3.8127 - mae: 1.3802 - val_loss: 11.8481 - val_mae: 2.4302\n",
      "Epoch 67/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 3.7753 - mae: 1.3737 - val_loss: 11.6331 - val_mae: 2.4089\n",
      "Epoch 68/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 3.7626 - mae: 1.3726 - val_loss: 11.5172 - val_mae: 2.3969\n",
      "Epoch 69/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 3.7465 - mae: 1.3687 - val_loss: 11.3942 - val_mae: 2.3858\n",
      "Epoch 70/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 3.7114 - mae: 1.3595 - val_loss: 11.6479 - val_mae: 2.4108\n",
      "Epoch 71/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 3.7254 - mae: 1.3622 - val_loss: 11.5622 - val_mae: 2.4037\n",
      "Epoch 72/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 3.8371 - mae: 1.4153 - val_loss: 11.8894 - val_mae: 2.4374\n",
      "Epoch 73/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 3.6902 - mae: 1.3579 - val_loss: 11.4173 - val_mae: 2.3741\n",
      "Epoch 74/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 3.6844 - mae: 1.3556 - val_loss: 11.7240 - val_mae: 2.4154\n",
      "Epoch 75/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 3.7367 - mae: 1.3850 - val_loss: 11.5995 - val_mae: 2.3996\n",
      "Epoch 76/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 3.6811 - mae: 1.3640 - val_loss: 11.7437 - val_mae: 2.4080\n",
      "Epoch 77/300\n",
      "270/270 [==============================] - 0s 229us/sample - loss: 3.6409 - mae: 1.3557 - val_loss: 11.5405 - val_mae: 2.3863\n",
      "Epoch 78/300\n",
      "270/270 [==============================] - 0s 240us/sample - loss: 3.6508 - mae: 1.3329 - val_loss: 11.9118 - val_mae: 2.4296\n",
      "Epoch 79/300\n",
      "270/270 [==============================] - 0s 229us/sample - loss: 3.7057 - mae: 1.3802 - val_loss: 12.1702 - val_mae: 2.4603\n",
      "Epoch 80/300\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 3.8137 - mae: 1.3717 - val_loss: 11.3148 - val_mae: 2.3647\n",
      "Epoch 81/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 3.7037 - mae: 1.3490 - val_loss: 12.8197 - val_mae: 2.5322\n",
      "Epoch 82/300\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 3.6706 - mae: 1.3521 - val_loss: 11.3825 - val_mae: 2.3886\n",
      "Epoch 83/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 3.6301 - mae: 1.3596 - val_loss: 11.9193 - val_mae: 2.4262\n",
      "Epoch 84/300\n",
      "270/270 [==============================] - 0s 203us/sample - loss: 3.6332 - mae: 1.3260 - val_loss: 11.8739 - val_mae: 2.4133\n",
      "Epoch 85/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 3.5848 - mae: 1.3539 - val_loss: 11.7609 - val_mae: 2.4220\n",
      "Epoch 86/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 3.5453 - mae: 1.3369 - val_loss: 11.7724 - val_mae: 2.4046\n",
      "Epoch 87/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 3.6220 - mae: 1.3511 - val_loss: 11.7023 - val_mae: 2.4012\n",
      "Epoch 88/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 3.5595 - mae: 1.3412 - val_loss: 11.5326 - val_mae: 2.3797\n",
      "Epoch 89/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 3.5514 - mae: 1.3371 - val_loss: 12.2142 - val_mae: 2.4532\n",
      "Epoch 90/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 3.5505 - mae: 1.3567 - val_loss: 11.6438 - val_mae: 2.3940\n",
      "Epoch 91/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 3.5623 - mae: 1.3264 - val_loss: 12.1753 - val_mae: 2.4372\n",
      "Epoch 92/300\n",
      "270/270 [==============================] - 0s 199us/sample - loss: 3.4727 - mae: 1.3040 - val_loss: 11.8258 - val_mae: 2.4199\n",
      "Epoch 93/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 3.5660 - mae: 1.3432 - val_loss: 11.6123 - val_mae: 2.4051\n",
      "Epoch 94/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 3.6565 - mae: 1.3706 - val_loss: 12.3457 - val_mae: 2.4615\n",
      "Epoch 95/300\n",
      "270/270 [==============================] - 0s 222us/sample - loss: 3.5538 - mae: 1.3589 - val_loss: 11.3331 - val_mae: 2.3657\n",
      "Epoch 96/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 3.4727 - mae: 1.3135 - val_loss: 12.2252 - val_mae: 2.4429\n",
      "Epoch 97/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 3.4509 - mae: 1.3161 - val_loss: 11.7369 - val_mae: 2.4105\n",
      "Epoch 98/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 3.4406 - mae: 1.3153 - val_loss: 11.8732 - val_mae: 2.4117\n",
      "Epoch 99/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 3.4357 - mae: 1.3057 - val_loss: 12.2189 - val_mae: 2.4413\n",
      "Epoch 100/300\n",
      "270/270 [==============================] - 0s 229us/sample - loss: 3.4174 - mae: 1.3242 - val_loss: 11.8312 - val_mae: 2.4099\n",
      "Epoch 101/300\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 3.3542 - mae: 1.3018 - val_loss: 12.0595 - val_mae: 2.4238\n",
      "Epoch 102/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 3.3946 - mae: 1.2994 - val_loss: 11.9990 - val_mae: 2.4242\n",
      "Epoch 103/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 3.4016 - mae: 1.3231 - val_loss: 12.0912 - val_mae: 2.4349\n",
      "Epoch 104/300\n",
      "270/270 [==============================] - 0s 177us/sample - loss: 3.4069 - mae: 1.3095 - val_loss: 12.1542 - val_mae: 2.4292\n",
      "Epoch 105/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 3.3619 - mae: 1.3185 - val_loss: 12.1480 - val_mae: 2.4347\n",
      "Epoch 106/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 3.3288 - mae: 1.2991 - val_loss: 11.6277 - val_mae: 2.3900\n",
      "Epoch 107/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 3.3787 - mae: 1.2975 - val_loss: 11.9071 - val_mae: 2.4162\n",
      "Epoch 108/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 3.3556 - mae: 1.3210 - val_loss: 12.7118 - val_mae: 2.4990\n",
      "Epoch 109/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 3.5275 - mae: 1.3412 - val_loss: 11.6059 - val_mae: 2.3898\n",
      "Epoch 110/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 3.3301 - mae: 1.3110 - val_loss: 12.5582 - val_mae: 2.4877\n",
      "Epoch 111/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 3.2400 - mae: 1.2947 - val_loss: 11.6499 - val_mae: 2.4220\n",
      "Epoch 112/300\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 3.3130 - mae: 1.2955 - val_loss: 12.2913 - val_mae: 2.4489\n",
      "Epoch 113/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 3.2639 - mae: 1.2917 - val_loss: 12.0176 - val_mae: 2.4215\n",
      "Epoch 114/300\n",
      "270/270 [==============================] - 0s 177us/sample - loss: 3.2085 - mae: 1.2721 - val_loss: 12.0086 - val_mae: 2.4219\n",
      "Epoch 115/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 3.2647 - mae: 1.2774 - val_loss: 12.4292 - val_mae: 2.4543\n",
      "Epoch 116/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 3.2336 - mae: 1.2876 - val_loss: 12.0158 - val_mae: 2.4217\n",
      "Epoch 117/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 3.2578 - mae: 1.2760 - val_loss: 12.1549 - val_mae: 2.4427\n",
      "Epoch 118/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 3.2680 - mae: 1.2748 - val_loss: 11.8858 - val_mae: 2.4109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/300\n",
      "270/270 [==============================] - 0s 199us/sample - loss: 3.2005 - mae: 1.2778 - val_loss: 12.2934 - val_mae: 2.4519\n",
      "Epoch 120/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 3.2328 - mae: 1.2821 - val_loss: 12.2458 - val_mae: 2.4408\n",
      "Epoch 121/300\n",
      "270/270 [==============================] - 0s 177us/sample - loss: 3.1850 - mae: 1.2548 - val_loss: 12.1507 - val_mae: 2.4265\n",
      "Epoch 122/300\n",
      "270/270 [==============================] - 0s 203us/sample - loss: 3.1687 - mae: 1.2618 - val_loss: 11.9413 - val_mae: 2.4180\n",
      "Epoch 123/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 3.1434 - mae: 1.2616 - val_loss: 12.2551 - val_mae: 2.4476\n",
      "Epoch 124/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 3.1454 - mae: 1.2545 - val_loss: 12.3876 - val_mae: 2.4582\n",
      "Epoch 125/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 3.1396 - mae: 1.2628 - val_loss: 12.4710 - val_mae: 2.4597\n",
      "Epoch 126/300\n",
      "270/270 [==============================] - 0s 203us/sample - loss: 3.1219 - mae: 1.2493 - val_loss: 12.3583 - val_mae: 2.4456\n",
      "Epoch 127/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 3.1398 - mae: 1.2720 - val_loss: 12.3016 - val_mae: 2.4584\n",
      "Epoch 128/300\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 3.0988 - mae: 1.2621 - val_loss: 12.3794 - val_mae: 2.4571\n",
      "Epoch 129/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 3.1254 - mae: 1.2454 - val_loss: 12.5523 - val_mae: 2.4749\n",
      "Epoch 130/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 3.0734 - mae: 1.2596 - val_loss: 12.6985 - val_mae: 2.4744\n",
      "Epoch 131/300\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 3.1990 - mae: 1.2732 - val_loss: 11.9311 - val_mae: 2.4105\n",
      "Epoch 132/300\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 3.1175 - mae: 1.2718 - val_loss: 12.3790 - val_mae: 2.4637\n",
      "Epoch 133/300\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 3.0700 - mae: 1.2432 - val_loss: 12.6512 - val_mae: 2.4778\n",
      "Epoch 134/300\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 3.0084 - mae: 1.2218 - val_loss: 12.1536 - val_mae: 2.4439\n",
      "Epoch 135/300\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 3.0906 - mae: 1.2717 - val_loss: 12.4424 - val_mae: 2.4502\n",
      "Epoch 136/300\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 3.0522 - mae: 1.2396 - val_loss: 12.7704 - val_mae: 2.4837\n",
      "Epoch 137/300\n",
      "270/270 [==============================] - 0s 240us/sample - loss: 3.0478 - mae: 1.2391 - val_loss: 12.2267 - val_mae: 2.4353\n",
      "Epoch 138/300\n",
      "270/270 [==============================] - 0s 218us/sample - loss: 3.0030 - mae: 1.2413 - val_loss: 12.7428 - val_mae: 2.4811\n",
      "Epoch 139/300\n",
      "270/270 [==============================] - 0s 203us/sample - loss: 3.0632 - mae: 1.2285 - val_loss: 12.6037 - val_mae: 2.4670\n",
      "Epoch 140/300\n",
      "270/270 [==============================] - 0s 277us/sample - loss: 2.9725 - mae: 1.2383 - val_loss: 12.6843 - val_mae: 2.4753\n",
      "Epoch 141/300\n",
      "270/270 [==============================] - 0s 236us/sample - loss: 3.0366 - mae: 1.2439 - val_loss: 12.6737 - val_mae: 2.4701\n",
      "Epoch 142/300\n",
      "270/270 [==============================] - 0s 207us/sample - loss: 3.0141 - mae: 1.2419 - val_loss: 12.2576 - val_mae: 2.4534\n",
      "Epoch 143/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 3.0325 - mae: 1.2483 - val_loss: 12.8101 - val_mae: 2.4848\n",
      "Epoch 144/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 2.9602 - mae: 1.2138 - val_loss: 12.4428 - val_mae: 2.4484\n",
      "Epoch 145/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 2.9306 - mae: 1.2201 - val_loss: 13.0405 - val_mae: 2.5106\n",
      "Epoch 146/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 2.9633 - mae: 1.2431 - val_loss: 12.5204 - val_mae: 2.4607\n",
      "Epoch 147/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 2.9213 - mae: 1.2190 - val_loss: 12.7049 - val_mae: 2.4712\n",
      "Epoch 148/300\n",
      "270/270 [==============================] - 0s 177us/sample - loss: 2.9053 - mae: 1.2132 - val_loss: 12.7409 - val_mae: 2.4848\n",
      "Epoch 149/300\n",
      "270/270 [==============================] - 0s 199us/sample - loss: 2.9281 - mae: 1.2052 - val_loss: 12.7936 - val_mae: 2.4797\n",
      "Epoch 150/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 2.8484 - mae: 1.1997 - val_loss: 12.8766 - val_mae: 2.4864\n",
      "Epoch 151/300\n",
      "270/270 [==============================] - 0s 177us/sample - loss: 2.9382 - mae: 1.2149 - val_loss: 12.4651 - val_mae: 2.4470\n",
      "Epoch 152/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 2.8525 - mae: 1.2020 - val_loss: 12.7683 - val_mae: 2.4737\n",
      "Epoch 153/300\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 2.8698 - mae: 1.2097 - val_loss: 13.1858 - val_mae: 2.5073\n",
      "Epoch 154/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 2.9073 - mae: 1.2189 - val_loss: 12.4036 - val_mae: 2.4407\n",
      "Epoch 155/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 2.8550 - mae: 1.1989 - val_loss: 12.9010 - val_mae: 2.4708\n",
      "Epoch 156/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 2.8575 - mae: 1.2151 - val_loss: 13.1494 - val_mae: 2.4903\n",
      "Epoch 157/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 2.8484 - mae: 1.2044 - val_loss: 13.0793 - val_mae: 2.4920\n",
      "Epoch 158/300\n",
      "270/270 [==============================] - 0s 177us/sample - loss: 2.8028 - mae: 1.2001 - val_loss: 13.1657 - val_mae: 2.5039\n",
      "Epoch 159/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 2.8151 - mae: 1.2035 - val_loss: 13.1473 - val_mae: 2.4924\n",
      "Epoch 160/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 2.7985 - mae: 1.1880 - val_loss: 12.7233 - val_mae: 2.4537\n",
      "Epoch 161/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 2.8623 - mae: 1.2193 - val_loss: 12.9406 - val_mae: 2.4735\n",
      "Epoch 162/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 2.8920 - mae: 1.1994 - val_loss: 13.5111 - val_mae: 2.5286\n",
      "Epoch 163/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 2.7810 - mae: 1.2002 - val_loss: 12.9055 - val_mae: 2.4852\n",
      "Epoch 164/300\n",
      "270/270 [==============================] - 0s 205us/sample - loss: 2.7753 - mae: 1.1996 - val_loss: 13.0900 - val_mae: 2.4886\n",
      "Epoch 165/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 2.8909 - mae: 1.2280 - val_loss: 13.5220 - val_mae: 2.5247\n",
      "Epoch 166/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 2.8829 - mae: 1.2480 - val_loss: 13.0363 - val_mae: 2.4848\n",
      "Epoch 167/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 2.7618 - mae: 1.1952 - val_loss: 12.8914 - val_mae: 2.4673\n",
      "Epoch 168/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 2.7119 - mae: 1.1765 - val_loss: 13.5879 - val_mae: 2.5406\n",
      "Epoch 169/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 2.7664 - mae: 1.1750 - val_loss: 12.6150 - val_mae: 2.4498\n",
      "Epoch 170/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 2.8286 - mae: 1.2206 - val_loss: 13.7941 - val_mae: 2.5535\n",
      "Epoch 171/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 2.8026 - mae: 1.1880 - val_loss: 12.8253 - val_mae: 2.4667\n",
      "Epoch 172/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 2.6889 - mae: 1.1900 - val_loss: 13.4505 - val_mae: 2.5263\n",
      "Epoch 173/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 2.6722 - mae: 1.1870 - val_loss: 13.4653 - val_mae: 2.5086\n",
      "Epoch 174/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 2.6807 - mae: 1.1792 - val_loss: 13.8039 - val_mae: 2.5569\n",
      "Epoch 175/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 2.6257 - mae: 1.1675 - val_loss: 13.4696 - val_mae: 2.5218\n",
      "Epoch 176/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 2.7142 - mae: 1.1650 - val_loss: 13.3689 - val_mae: 2.5164\n",
      "Epoch 177/300\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 2.6309 - mae: 1.1512 - val_loss: 14.0026 - val_mae: 2.5583\n",
      "Epoch 178/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 2.5916 - mae: 1.1501 - val_loss: 13.4046 - val_mae: 2.5107\n",
      "Epoch 179/300\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 2.5583 - mae: 1.1353 - val_loss: 13.2381 - val_mae: 2.4987\n",
      "Epoch 180/300\n",
      "270/270 [==============================] - 0s 199us/sample - loss: 2.6106 - mae: 1.1337 - val_loss: 13.4172 - val_mae: 2.5134\n",
      "Epoch 181/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 2.6003 - mae: 1.1800 - val_loss: 13.7628 - val_mae: 2.5532\n",
      "Epoch 182/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 2.5740 - mae: 1.1428 - val_loss: 13.6597 - val_mae: 2.5425\n",
      "Epoch 183/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 2.5731 - mae: 1.1381 - val_loss: 13.6890 - val_mae: 2.5322\n",
      "Epoch 184/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 2.5840 - mae: 1.1694 - val_loss: 13.9331 - val_mae: 2.5578\n",
      "Epoch 185/300\n",
      "270/270 [==============================] - 0s 199us/sample - loss: 2.5206 - mae: 1.1388 - val_loss: 13.7794 - val_mae: 2.5352\n",
      "Epoch 186/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 2.5666 - mae: 1.1369 - val_loss: 13.8769 - val_mae: 2.5555\n",
      "Epoch 187/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 2.5500 - mae: 1.1671 - val_loss: 13.8518 - val_mae: 2.5425\n",
      "Epoch 188/300\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 2.5418 - mae: 1.1342 - val_loss: 13.3794 - val_mae: 2.5024\n",
      "Epoch 189/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 2.5174 - mae: 1.1471 - val_loss: 14.1905 - val_mae: 2.5825\n",
      "Epoch 190/300\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 2.5268 - mae: 1.1456 - val_loss: 13.8549 - val_mae: 2.5349\n",
      "Epoch 191/300\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 2.4917 - mae: 1.1497 - val_loss: 13.8726 - val_mae: 2.5358\n",
      "Epoch 192/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 2.4809 - mae: 1.1327 - val_loss: 13.4019 - val_mae: 2.5012\n",
      "Epoch 193/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 2.4451 - mae: 1.1143 - val_loss: 13.8433 - val_mae: 2.5410\n",
      "Epoch 194/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 2.4225 - mae: 1.1061 - val_loss: 14.5101 - val_mae: 2.6011\n",
      "Epoch 195/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 2.5256 - mae: 1.1501 - val_loss: 13.9769 - val_mae: 2.5506\n",
      "Epoch 196/300\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 2.4582 - mae: 1.1212 - val_loss: 13.7656 - val_mae: 2.5265\n",
      "Epoch 197/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 2.4280 - mae: 1.1213 - val_loss: 14.3002 - val_mae: 2.5697\n",
      "Epoch 198/300\n",
      "270/270 [==============================] - 0s 177us/sample - loss: 2.4410 - mae: 1.1243 - val_loss: 14.0538 - val_mae: 2.5428\n",
      "Epoch 199/300\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 2.4219 - mae: 1.1074 - val_loss: 13.9060 - val_mae: 2.5310\n",
      "Epoch 200/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 2.3715 - mae: 1.0968 - val_loss: 14.1149 - val_mae: 2.5594\n",
      "Epoch 201/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 2.3641 - mae: 1.1030 - val_loss: 14.1173 - val_mae: 2.5482\n",
      "Epoch 202/300\n",
      "270/270 [==============================] - 0s 177us/sample - loss: 2.4231 - mae: 1.1159 - val_loss: 14.0837 - val_mae: 2.5463\n",
      "Epoch 203/300\n",
      "270/270 [==============================] - 0s 203us/sample - loss: 2.3426 - mae: 1.0798 - val_loss: 14.2697 - val_mae: 2.5695\n",
      "Epoch 204/300\n",
      "270/270 [==============================] - 0s 203us/sample - loss: 2.4271 - mae: 1.1351 - val_loss: 14.0536 - val_mae: 2.5535\n",
      "Epoch 205/300\n",
      "270/270 [==============================] - 0s 266us/sample - loss: 2.4354 - mae: 1.1188 - val_loss: 14.5910 - val_mae: 2.5968\n",
      "Epoch 206/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 2.5431 - mae: 1.1853 - val_loss: 14.5160 - val_mae: 2.6018\n",
      "Epoch 207/300\n",
      "270/270 [==============================] - 0s 211us/sample - loss: 2.4392 - mae: 1.1089 - val_loss: 14.1333 - val_mae: 2.5558\n",
      "Epoch 208/300\n",
      "270/270 [==============================] - 0s 266us/sample - loss: 2.3886 - mae: 1.1188 - val_loss: 14.0353 - val_mae: 2.5458\n",
      "Epoch 209/300\n",
      "270/270 [==============================] - 0s 236us/sample - loss: 2.3352 - mae: 1.1009 - val_loss: 14.2737 - val_mae: 2.5642\n",
      "Epoch 210/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 2.2967 - mae: 1.0910 - val_loss: 14.2004 - val_mae: 2.5844\n",
      "Epoch 211/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 2.3454 - mae: 1.0954 - val_loss: 14.6560 - val_mae: 2.5954\n",
      "Epoch 212/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 2.3429 - mae: 1.0845 - val_loss: 13.9748 - val_mae: 2.5531\n",
      "Epoch 213/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 2.3260 - mae: 1.1086 - val_loss: 14.5660 - val_mae: 2.5899\n",
      "Epoch 214/300\n",
      "270/270 [==============================] - 0s 244us/sample - loss: 2.2742 - mae: 1.0832 - val_loss: 13.9983 - val_mae: 2.5524\n",
      "Epoch 215/300\n",
      "270/270 [==============================] - 0s 236us/sample - loss: 2.3479 - mae: 1.1062 - val_loss: 14.3070 - val_mae: 2.5523\n",
      "Epoch 216/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 2.3768 - mae: 1.1033 - val_loss: 15.0585 - val_mae: 2.6199\n",
      "Epoch 217/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 2.3138 - mae: 1.0891 - val_loss: 14.4182 - val_mae: 2.5709\n",
      "Epoch 218/300\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 2.3200 - mae: 1.1035 - val_loss: 14.3014 - val_mae: 2.5599\n",
      "Epoch 219/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 2.2980 - mae: 1.0799 - val_loss: 14.1127 - val_mae: 2.5388\n",
      "Epoch 220/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 2.2404 - mae: 1.0783 - val_loss: 15.1823 - val_mae: 2.6303\n",
      "Epoch 221/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 2.2358 - mae: 1.0588 - val_loss: 14.4913 - val_mae: 2.5684\n",
      "Epoch 222/300\n",
      "270/270 [==============================] - 0s 199us/sample - loss: 2.3082 - mae: 1.0987 - val_loss: 14.0785 - val_mae: 2.5331\n",
      "Epoch 223/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 2.2328 - mae: 1.0684 - val_loss: 14.2335 - val_mae: 2.5374\n",
      "Epoch 224/300\n",
      "270/270 [==============================] - 0s 259us/sample - loss: 2.1716 - mae: 1.0419 - val_loss: 14.9305 - val_mae: 2.6082\n",
      "Epoch 225/300\n",
      "270/270 [==============================] - 0s 199us/sample - loss: 2.2452 - mae: 1.1025 - val_loss: 14.6428 - val_mae: 2.5834\n",
      "Epoch 226/300\n",
      "270/270 [==============================] - 0s 199us/sample - loss: 2.2322 - mae: 1.0726 - val_loss: 14.6636 - val_mae: 2.5857\n",
      "Epoch 227/300\n",
      "270/270 [==============================] - 0s 236us/sample - loss: 2.1966 - mae: 1.0584 - val_loss: 14.3192 - val_mae: 2.5491\n",
      "Epoch 228/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 2.1302 - mae: 1.0420 - val_loss: 14.8292 - val_mae: 2.5929\n",
      "Epoch 229/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 2.1446 - mae: 1.0483 - val_loss: 14.4142 - val_mae: 2.5606\n",
      "Epoch 230/300\n",
      "270/270 [==============================] - 0s 240us/sample - loss: 2.1416 - mae: 1.0424 - val_loss: 14.7438 - val_mae: 2.5775\n",
      "Epoch 231/300\n",
      "270/270 [==============================] - 0s 240us/sample - loss: 2.1680 - mae: 1.0366 - val_loss: 14.8343 - val_mae: 2.5874\n",
      "Epoch 232/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 2.1227 - mae: 1.0458 - val_loss: 14.6189 - val_mae: 2.5628\n",
      "Epoch 233/300\n",
      "270/270 [==============================] - ETA: 0s - loss: 1.7314 - mae: 1.011 - 0s 188us/sample - loss: 2.1536 - mae: 1.0521 - val_loss: 14.8892 - val_mae: 2.5909\n",
      "Epoch 234/300\n",
      "270/270 [==============================] - 0s 211us/sample - loss: 2.1006 - mae: 1.0273 - val_loss: 15.0449 - val_mae: 2.6029\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 240us/sample - loss: 2.1292 - mae: 1.0472 - val_loss: 14.5450 - val_mae: 2.5586\n",
      "Epoch 236/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 2.3498 - mae: 1.0936 - val_loss: 14.9907 - val_mae: 2.5982\n",
      "Epoch 237/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 2.1832 - mae: 1.0983 - val_loss: 14.9271 - val_mae: 2.5931\n",
      "Epoch 238/300\n",
      "270/270 [==============================] - 0s 211us/sample - loss: 2.0806 - mae: 1.0294 - val_loss: 14.5862 - val_mae: 2.5614\n",
      "Epoch 239/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 2.1163 - mae: 1.0463 - val_loss: 15.1678 - val_mae: 2.6196\n",
      "Epoch 240/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 2.0893 - mae: 1.0465 - val_loss: 14.7093 - val_mae: 2.5657\n",
      "Epoch 241/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 2.0939 - mae: 1.0309 - val_loss: 15.1122 - val_mae: 2.6056\n",
      "Epoch 242/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 2.0752 - mae: 1.0191 - val_loss: 15.0230 - val_mae: 2.5974\n",
      "Epoch 243/300\n",
      "270/270 [==============================] - 0s 218us/sample - loss: 2.0789 - mae: 1.0267 - val_loss: 14.7545 - val_mae: 2.5725\n",
      "Epoch 244/300\n",
      "270/270 [==============================] - 0s 233us/sample - loss: 2.0177 - mae: 1.0213 - val_loss: 14.9713 - val_mae: 2.5870\n",
      "Epoch 245/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 2.0738 - mae: 1.0229 - val_loss: 15.1462 - val_mae: 2.6072\n",
      "Epoch 246/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 2.1521 - mae: 1.0755 - val_loss: 15.2471 - val_mae: 2.6100\n",
      "Epoch 247/300\n",
      "270/270 [==============================] - 0s 177us/sample - loss: 2.1246 - mae: 1.0469 - val_loss: 15.2690 - val_mae: 2.6137\n",
      "Epoch 248/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 2.2034 - mae: 1.0947 - val_loss: 15.1774 - val_mae: 2.6037\n",
      "Epoch 249/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 2.1420 - mae: 1.0671 - val_loss: 15.1455 - val_mae: 2.6103\n",
      "Epoch 250/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 2.1178 - mae: 1.0671 - val_loss: 15.0700 - val_mae: 2.5915\n",
      "Epoch 251/300\n",
      "270/270 [==============================] - 0s 199us/sample - loss: 2.0971 - mae: 1.0527 - val_loss: 15.2680 - val_mae: 2.6067\n",
      "Epoch 252/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 2.0062 - mae: 1.0328 - val_loss: 15.2688 - val_mae: 2.6087\n",
      "Epoch 253/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 1.9583 - mae: 0.9954 - val_loss: 14.9216 - val_mae: 2.5792\n",
      "Epoch 254/300\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 1.9820 - mae: 1.0052 - val_loss: 15.6916 - val_mae: 2.6404\n",
      "Epoch 255/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 1.9855 - mae: 1.0125 - val_loss: 15.0188 - val_mae: 2.5768\n",
      "Epoch 256/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 2.0030 - mae: 1.0104 - val_loss: 15.4934 - val_mae: 2.6242\n",
      "Epoch 257/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 1.9778 - mae: 0.9989 - val_loss: 15.4426 - val_mae: 2.6161\n",
      "Epoch 258/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 1.9225 - mae: 0.9930 - val_loss: 15.3578 - val_mae: 2.5940\n",
      "Epoch 259/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 1.9292 - mae: 0.9871 - val_loss: 15.4507 - val_mae: 2.6147\n",
      "Epoch 260/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 1.9396 - mae: 1.0113 - val_loss: 15.6104 - val_mae: 2.6066\n",
      "Epoch 261/300\n",
      "270/270 [==============================] - 0s 240us/sample - loss: 1.9966 - mae: 1.0051 - val_loss: 15.2457 - val_mae: 2.5951\n",
      "Epoch 262/300\n",
      "270/270 [==============================] - 0s 233us/sample - loss: 1.9046 - mae: 0.9954 - val_loss: 15.8789 - val_mae: 2.6434\n",
      "Epoch 263/300\n",
      "270/270 [==============================] - 0s 233us/sample - loss: 1.9026 - mae: 0.9922 - val_loss: 15.1679 - val_mae: 2.5819\n",
      "Epoch 264/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 1.9499 - mae: 0.9848 - val_loss: 15.2826 - val_mae: 2.5901\n",
      "Epoch 265/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 1.8741 - mae: 0.9701 - val_loss: 15.7075 - val_mae: 2.6159\n",
      "Epoch 266/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 1.9403 - mae: 1.0160 - val_loss: 15.7701 - val_mae: 2.6230\n",
      "Epoch 267/300\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 1.8960 - mae: 0.9689 - val_loss: 15.7061 - val_mae: 2.6245\n",
      "Epoch 268/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 1.8723 - mae: 0.9823 - val_loss: 15.7051 - val_mae: 2.6176\n",
      "Epoch 269/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 1.8510 - mae: 0.9627 - val_loss: 15.6995 - val_mae: 2.6100\n",
      "Epoch 270/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 1.8391 - mae: 0.9600 - val_loss: 15.6382 - val_mae: 2.6154\n",
      "Epoch 271/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 1.8514 - mae: 0.9824 - val_loss: 15.7996 - val_mae: 2.6274\n",
      "Epoch 272/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 1.8757 - mae: 0.9685 - val_loss: 16.1985 - val_mae: 2.6621\n",
      "Epoch 273/300\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 2.0471 - mae: 1.0568 - val_loss: 15.3585 - val_mae: 2.5934\n",
      "Epoch 274/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 1.9444 - mae: 1.0073 - val_loss: 15.8302 - val_mae: 2.6342\n",
      "Epoch 275/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 1.8892 - mae: 0.9998 - val_loss: 15.9438 - val_mae: 2.6326\n",
      "Epoch 276/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 1.8271 - mae: 0.9569 - val_loss: 15.7008 - val_mae: 2.6174\n",
      "Epoch 277/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 1.8396 - mae: 0.9708 - val_loss: 16.0157 - val_mae: 2.6402\n",
      "Epoch 278/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 1.9511 - mae: 0.9945 - val_loss: 15.9487 - val_mae: 2.6294\n",
      "Epoch 279/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 1.8528 - mae: 0.9928 - val_loss: 15.4872 - val_mae: 2.5763\n",
      "Epoch 280/300\n",
      "270/270 [==============================] - 0s 199us/sample - loss: 1.8639 - mae: 0.9700 - val_loss: 15.9690 - val_mae: 2.6317\n",
      "Epoch 281/300\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 1.9082 - mae: 0.9877 - val_loss: 16.1126 - val_mae: 2.6465\n",
      "Epoch 282/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 1.8277 - mae: 0.9557 - val_loss: 15.9490 - val_mae: 2.6369\n",
      "Epoch 283/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 1.9407 - mae: 1.0182 - val_loss: 15.8982 - val_mae: 2.6171\n",
      "Epoch 284/300\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 1.8041 - mae: 0.9562 - val_loss: 16.0780 - val_mae: 2.6306\n",
      "Epoch 285/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 1.7458 - mae: 0.9378 - val_loss: 16.0356 - val_mae: 2.6290\n",
      "Epoch 286/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 1.7434 - mae: 0.9404 - val_loss: 15.9556 - val_mae: 2.6244\n",
      "Epoch 287/300\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 1.7496 - mae: 0.9483 - val_loss: 16.0948 - val_mae: 2.6394\n",
      "Epoch 288/300\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 1.7706 - mae: 0.9387 - val_loss: 16.1290 - val_mae: 2.6310\n",
      "Epoch 289/300\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 1.7309 - mae: 0.9321 - val_loss: 16.1868 - val_mae: 2.6361\n",
      "Epoch 290/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 1.7345 - mae: 0.9436 - val_loss: 15.9594 - val_mae: 2.6093\n",
      "Epoch 291/300\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 1.7908 - mae: 0.9437 - val_loss: 16.1561 - val_mae: 2.6347\n",
      "Epoch 292/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 1.8083 - mae: 0.9792 - val_loss: 16.2201 - val_mae: 2.6375\n",
      "Epoch 293/300\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 1.7388 - mae: 0.9339 - val_loss: 16.3233 - val_mae: 2.6328\n",
      "Epoch 294/300\n",
      "270/270 [==============================] - 0s 199us/sample - loss: 1.7301 - mae: 0.9422 - val_loss: 16.0646 - val_mae: 2.6257\n",
      "Epoch 295/300\n",
      "270/270 [==============================] - 0s 177us/sample - loss: 1.7293 - mae: 0.9366 - val_loss: 16.1343 - val_mae: 2.6315\n",
      "Epoch 296/300\n",
      "270/270 [==============================] - 0s 211us/sample - loss: 1.7593 - mae: 0.9505 - val_loss: 15.6525 - val_mae: 2.5895\n",
      "Epoch 297/300\n",
      "270/270 [==============================] - 0s 199us/sample - loss: 1.7462 - mae: 0.9447 - val_loss: 16.3006 - val_mae: 2.6261\n",
      "Epoch 298/300\n",
      "270/270 [==============================] - 0s 229us/sample - loss: 1.7613 - mae: 0.9682 - val_loss: 16.3331 - val_mae: 2.6377\n",
      "Epoch 299/300\n",
      "270/270 [==============================] - 0s 214us/sample - loss: 1.7788 - mae: 0.9595 - val_loss: 16.6452 - val_mae: 2.6630\n",
      "Epoch 300/300\n",
      "270/270 [==============================] - 0s 225us/sample - loss: 1.7199 - mae: 0.9295 - val_loss: 15.7849 - val_mae: 2.5951\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 300, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "102/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 401us/sample - loss: 6.6492 - mae: 2.4881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.642765468242121, 2.4881368]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 269 samples, validate on 135 samples\n",
      "Epoch 1/300\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 565.9106 - mae: 21.9255 - val_loss: 538.9541 - val_mae: 21.3793\n",
      "Epoch 2/300\n",
      "269/269 [==============================] - 0s 144us/sample - loss: 538.3979 - mae: 21.3141 - val_loss: 513.9776 - val_mae: 20.7946\n",
      "Epoch 3/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 510.7581 - mae: 20.6572 - val_loss: 485.7552 - val_mae: 20.1144\n",
      "Epoch 4/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 476.9302 - mae: 19.8647 - val_loss: 451.8621 - val_mae: 19.2750\n",
      "Epoch 5/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 437.2059 - mae: 18.8964 - val_loss: 410.8081 - val_mae: 18.2215\n",
      "Epoch 6/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 389.8439 - mae: 17.6701 - val_loss: 363.0513 - val_mae: 16.9385\n",
      "Epoch 7/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 334.3333 - mae: 16.2110 - val_loss: 308.0386 - val_mae: 15.3718\n",
      "Epoch 8/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 275.1936 - mae: 14.5091 - val_loss: 248.0506 - val_mae: 13.5025\n",
      "Epoch 9/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 213.2319 - mae: 12.5016 - val_loss: 190.5112 - val_mae: 11.4929\n",
      "Epoch 10/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 158.9758 - mae: 10.3900 - val_loss: 139.8619 - val_mae: 9.5450\n",
      "Epoch 11/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 115.7494 - mae: 8.4701 - val_loss: 104.1860 - val_mae: 7.9787\n",
      "Epoch 12/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 89.6016 - mae: 7.2082 - val_loss: 80.9191 - val_mae: 6.8697\n",
      "Epoch 13/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 75.5594 - mae: 6.5590 - val_loss: 67.1346 - val_mae: 6.1803\n",
      "Epoch 14/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 65.5835 - mae: 6.2087 - val_loss: 57.7104 - val_mae: 5.7023\n",
      "Epoch 15/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 57.4348 - mae: 5.8261 - val_loss: 50.5241 - val_mae: 5.3089\n",
      "Epoch 16/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 50.4972 - mae: 5.4437 - val_loss: 45.1586 - val_mae: 4.9864\n",
      "Epoch 17/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 45.2412 - mae: 5.1341 - val_loss: 40.4781 - val_mae: 4.6780\n",
      "Epoch 18/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 40.6181 - mae: 4.8217 - val_loss: 36.7817 - val_mae: 4.4077\n",
      "Epoch 19/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 36.8052 - mae: 4.5501 - val_loss: 33.7877 - val_mae: 4.2246\n",
      "Epoch 20/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 34.1603 - mae: 4.3407 - val_loss: 30.9326 - val_mae: 4.0533\n",
      "Epoch 21/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 31.4659 - mae: 4.1386 - val_loss: 29.2972 - val_mae: 3.9377\n",
      "Epoch 22/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 29.5339 - mae: 3.9493 - val_loss: 28.2751 - val_mae: 3.8499\n",
      "Epoch 23/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 28.0481 - mae: 3.7901 - val_loss: 26.9448 - val_mae: 3.7506\n",
      "Epoch 24/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 26.5993 - mae: 3.6516 - val_loss: 26.1223 - val_mae: 3.6846\n",
      "Epoch 25/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 25.6112 - mae: 3.5612 - val_loss: 25.3324 - val_mae: 3.6491\n",
      "Epoch 26/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 24.6369 - mae: 3.4975 - val_loss: 24.7081 - val_mae: 3.6086\n",
      "Epoch 27/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 23.8205 - mae: 3.4153 - val_loss: 24.3979 - val_mae: 3.5821\n",
      "Epoch 28/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 23.1286 - mae: 3.3407 - val_loss: 24.0785 - val_mae: 3.5609\n",
      "Epoch 29/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 22.5226 - mae: 3.2693 - val_loss: 23.9764 - val_mae: 3.5417\n",
      "Epoch 30/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 21.8668 - mae: 3.2015 - val_loss: 23.5921 - val_mae: 3.5249\n",
      "Epoch 31/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 21.3373 - mae: 3.1682 - val_loss: 23.0998 - val_mae: 3.5110\n",
      "Epoch 32/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 20.7915 - mae: 3.1300 - val_loss: 22.7731 - val_mae: 3.4907\n",
      "Epoch 33/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 20.3521 - mae: 3.0893 - val_loss: 22.4838 - val_mae: 3.4705\n",
      "Epoch 34/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 19.8890 - mae: 3.0530 - val_loss: 22.1117 - val_mae: 3.4437\n",
      "Epoch 35/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 19.4871 - mae: 3.0200 - val_loss: 21.8487 - val_mae: 3.4271\n",
      "Epoch 36/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 19.1095 - mae: 2.9867 - val_loss: 21.6875 - val_mae: 3.4152\n",
      "Epoch 37/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 18.6741 - mae: 2.9496 - val_loss: 21.4970 - val_mae: 3.3999\n",
      "Epoch 38/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 18.3108 - mae: 2.9169 - val_loss: 21.3260 - val_mae: 3.3879\n",
      "Epoch 39/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 18.0325 - mae: 2.8899 - val_loss: 21.0393 - val_mae: 3.3662\n",
      "Epoch 40/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 17.7012 - mae: 2.8640 - val_loss: 20.9147 - val_mae: 3.3448\n",
      "Epoch 41/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 17.3975 - mae: 2.8311 - val_loss: 20.6145 - val_mae: 3.3379\n",
      "Epoch 42/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 17.1423 - mae: 2.8317 - val_loss: 20.4257 - val_mae: 3.3280\n",
      "Epoch 43/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 16.7665 - mae: 2.7985 - val_loss: 20.3058 - val_mae: 3.3091\n",
      "Epoch 44/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 16.4388 - mae: 2.7684 - val_loss: 20.1310 - val_mae: 3.2919\n",
      "Epoch 45/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 16.2060 - mae: 2.7570 - val_loss: 19.8576 - val_mae: 3.2792\n",
      "Epoch 46/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 15.9404 - mae: 2.7399 - val_loss: 19.7842 - val_mae: 3.2721\n",
      "Epoch 47/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 15.6552 - mae: 2.7131 - val_loss: 19.6604 - val_mae: 3.2586\n",
      "Epoch 48/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 15.5340 - mae: 2.6929 - val_loss: 19.6197 - val_mae: 3.2444\n",
      "Epoch 49/300\n",
      "269/269 [==============================] - 0s 151us/sample - loss: 15.2507 - mae: 2.6675 - val_loss: 19.2705 - val_mae: 3.2339\n",
      "Epoch 50/300\n",
      "269/269 [==============================] - 0s 159us/sample - loss: 15.0585 - mae: 2.6619 - val_loss: 19.0912 - val_mae: 3.2350\n",
      "Epoch 51/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 14.8253 - mae: 2.6433 - val_loss: 18.9599 - val_mae: 3.2078\n",
      "Epoch 52/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 14.5984 - mae: 2.6137 - val_loss: 18.8639 - val_mae: 3.1877\n",
      "Epoch 53/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 14.3976 - mae: 2.6048 - val_loss: 18.6644 - val_mae: 3.1826\n",
      "Epoch 54/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 14.2706 - mae: 2.5925 - val_loss: 18.5343 - val_mae: 3.1730\n",
      "Epoch 55/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 14.0423 - mae: 2.5753 - val_loss: 18.5302 - val_mae: 3.1795\n",
      "Epoch 56/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 13.8807 - mae: 2.5607 - val_loss: 18.4378 - val_mae: 3.1773\n",
      "Epoch 57/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 13.7435 - mae: 2.5489 - val_loss: 18.3245 - val_mae: 3.1626\n",
      "Epoch 58/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 13.5550 - mae: 2.5322 - val_loss: 18.3009 - val_mae: 3.1663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 13.4213 - mae: 2.5223 - val_loss: 18.2254 - val_mae: 3.1593\n",
      "Epoch 60/300\n",
      "269/269 [==============================] - 0s 148us/sample - loss: 13.4277 - mae: 2.5262 - val_loss: 17.9807 - val_mae: 3.1568\n",
      "Epoch 61/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 13.1107 - mae: 2.5038 - val_loss: 17.9966 - val_mae: 3.1400\n",
      "Epoch 62/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 13.0556 - mae: 2.4886 - val_loss: 17.9842 - val_mae: 3.1257\n",
      "Epoch 63/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 12.9333 - mae: 2.4769 - val_loss: 17.7920 - val_mae: 3.1286\n",
      "Epoch 64/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 12.7919 - mae: 2.4778 - val_loss: 17.5477 - val_mae: 3.1073\n",
      "Epoch 65/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 12.6307 - mae: 2.4619 - val_loss: 17.4470 - val_mae: 3.0966\n",
      "Epoch 66/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 12.4981 - mae: 2.4405 - val_loss: 17.4159 - val_mae: 3.0894\n",
      "Epoch 67/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 12.4769 - mae: 2.4288 - val_loss: 17.3963 - val_mae: 3.0834\n",
      "Epoch 68/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 12.3588 - mae: 2.4181 - val_loss: 17.2935 - val_mae: 3.0778\n",
      "Epoch 69/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 12.1600 - mae: 2.4075 - val_loss: 17.1721 - val_mae: 3.0881\n",
      "Epoch 70/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 12.1154 - mae: 2.4263 - val_loss: 17.0728 - val_mae: 3.0851\n",
      "Epoch 71/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 11.9800 - mae: 2.4170 - val_loss: 17.0457 - val_mae: 3.0850\n",
      "Epoch 72/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 11.9055 - mae: 2.4055 - val_loss: 17.0484 - val_mae: 3.0826\n",
      "Epoch 73/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 11.7846 - mae: 2.3802 - val_loss: 17.0091 - val_mae: 3.0710\n",
      "Epoch 74/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 11.6593 - mae: 2.3688 - val_loss: 16.9658 - val_mae: 3.0767\n",
      "Epoch 75/300\n",
      "269/269 [==============================] - 0s 149us/sample - loss: 11.5959 - mae: 2.3694 - val_loss: 16.9036 - val_mae: 3.0753\n",
      "Epoch 76/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 11.5372 - mae: 2.3777 - val_loss: 16.7825 - val_mae: 3.0701\n",
      "Epoch 77/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 11.4224 - mae: 2.3614 - val_loss: 16.7391 - val_mae: 3.0598\n",
      "Epoch 78/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 11.3062 - mae: 2.3475 - val_loss: 16.7000 - val_mae: 3.0632\n",
      "Epoch 79/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 11.2201 - mae: 2.3444 - val_loss: 16.4959 - val_mae: 3.0476\n",
      "Epoch 80/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 11.1587 - mae: 2.3524 - val_loss: 16.3711 - val_mae: 3.0392\n",
      "Epoch 81/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 11.0749 - mae: 2.3391 - val_loss: 16.3763 - val_mae: 3.0382\n",
      "Epoch 82/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 11.0723 - mae: 2.3250 - val_loss: 16.3610 - val_mae: 3.0155\n",
      "Epoch 83/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 11.0093 - mae: 2.3248 - val_loss: 16.2343 - val_mae: 3.0247\n",
      "Epoch 84/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 10.8156 - mae: 2.3166 - val_loss: 16.1716 - val_mae: 3.0260\n",
      "Epoch 85/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 10.6977 - mae: 2.2977 - val_loss: 16.1842 - val_mae: 3.0068\n",
      "Epoch 86/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 10.7016 - mae: 2.2904 - val_loss: 16.1095 - val_mae: 3.0018\n",
      "Epoch 87/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 10.5470 - mae: 2.2780 - val_loss: 15.9126 - val_mae: 2.9854\n",
      "Epoch 88/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 10.4945 - mae: 2.2786 - val_loss: 15.9289 - val_mae: 2.9865\n",
      "Epoch 89/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 10.4207 - mae: 2.2671 - val_loss: 15.9060 - val_mae: 2.9915\n",
      "Epoch 90/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 10.4052 - mae: 2.2634 - val_loss: 15.8988 - val_mae: 3.0007\n",
      "Epoch 91/300\n",
      "269/269 [==============================] - 0s 150us/sample - loss: 10.3213 - mae: 2.2545 - val_loss: 15.8567 - val_mae: 2.9867\n",
      "Epoch 92/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 10.2769 - mae: 2.2461 - val_loss: 15.7081 - val_mae: 2.9687\n",
      "Epoch 93/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 10.1550 - mae: 2.2424 - val_loss: 15.6752 - val_mae: 2.9722\n",
      "Epoch 94/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 10.1199 - mae: 2.2408 - val_loss: 15.6934 - val_mae: 2.9855\n",
      "Epoch 95/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 10.0757 - mae: 2.2264 - val_loss: 15.6693 - val_mae: 2.9739\n",
      "Epoch 96/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 10.0000 - mae: 2.2248 - val_loss: 15.6302 - val_mae: 2.9724\n",
      "Epoch 97/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 9.8993 - mae: 2.2160 - val_loss: 15.5844 - val_mae: 2.9606\n",
      "Epoch 98/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 9.8336 - mae: 2.1988 - val_loss: 15.6069 - val_mae: 2.9663\n",
      "Epoch 99/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 9.7696 - mae: 2.1932 - val_loss: 15.4557 - val_mae: 2.9512\n",
      "Epoch 100/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 9.7518 - mae: 2.1994 - val_loss: 15.5509 - val_mae: 2.9677\n",
      "Epoch 101/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 9.6442 - mae: 2.1909 - val_loss: 15.4896 - val_mae: 2.9642\n",
      "Epoch 102/300\n",
      "269/269 [==============================] - 0s 144us/sample - loss: 9.5943 - mae: 2.1821 - val_loss: 15.4176 - val_mae: 2.9454\n",
      "Epoch 103/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 9.5602 - mae: 2.1768 - val_loss: 15.4119 - val_mae: 2.9507\n",
      "Epoch 104/300\n",
      "269/269 [==============================] - 0s 153us/sample - loss: 9.4479 - mae: 2.1599 - val_loss: 15.3348 - val_mae: 2.9305\n",
      "Epoch 105/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 9.5261 - mae: 2.1651 - val_loss: 15.2481 - val_mae: 2.9296\n",
      "Epoch 106/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 9.3233 - mae: 2.1546 - val_loss: 15.2682 - val_mae: 2.9337\n",
      "Epoch 107/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 9.2943 - mae: 2.1494 - val_loss: 15.3182 - val_mae: 2.9458\n",
      "Epoch 108/300\n",
      "269/269 [==============================] - 0s 145us/sample - loss: 9.2327 - mae: 2.1334 - val_loss: 15.2629 - val_mae: 2.9293\n",
      "Epoch 109/300\n",
      "269/269 [==============================] - 0s 144us/sample - loss: 9.1789 - mae: 2.1192 - val_loss: 15.1795 - val_mae: 2.9186\n",
      "Epoch 110/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 9.0889 - mae: 2.1296 - val_loss: 15.1659 - val_mae: 2.9233\n",
      "Epoch 111/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 9.1551 - mae: 2.1299 - val_loss: 15.0872 - val_mae: 2.9136\n",
      "Epoch 112/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 9.1070 - mae: 2.1196 - val_loss: 15.0812 - val_mae: 2.9093\n",
      "Epoch 113/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 8.9583 - mae: 2.1060 - val_loss: 15.1269 - val_mae: 2.9199\n",
      "Epoch 114/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 8.9204 - mae: 2.1100 - val_loss: 15.0543 - val_mae: 2.9184\n",
      "Epoch 115/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 8.8689 - mae: 2.1019 - val_loss: 15.0493 - val_mae: 2.9148\n",
      "Epoch 116/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 8.7869 - mae: 2.0791 - val_loss: 14.9348 - val_mae: 2.8941\n",
      "Epoch 117/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 8.7502 - mae: 2.0818 - val_loss: 14.9197 - val_mae: 2.9000\n",
      "Epoch 118/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 8.8213 - mae: 2.0896 - val_loss: 14.9817 - val_mae: 2.9038\n",
      "Epoch 119/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 8.6467 - mae: 2.0761 - val_loss: 14.9300 - val_mae: 2.8973\n",
      "Epoch 120/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 8.5477 - mae: 2.0586 - val_loss: 14.9645 - val_mae: 2.8984\n",
      "Epoch 121/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 8.4870 - mae: 2.0496 - val_loss: 15.0216 - val_mae: 2.9169\n",
      "Epoch 122/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 8.4629 - mae: 2.0500 - val_loss: 14.8298 - val_mae: 2.8835\n",
      "Epoch 123/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 8.3809 - mae: 2.0359 - val_loss: 14.8248 - val_mae: 2.8876\n",
      "Epoch 124/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 8.3222 - mae: 2.0287 - val_loss: 14.7954 - val_mae: 2.8819\n",
      "Epoch 125/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 8.3429 - mae: 2.0321 - val_loss: 14.7420 - val_mae: 2.8826\n",
      "Epoch 126/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 8.2931 - mae: 2.0258 - val_loss: 14.6792 - val_mae: 2.8732\n",
      "Epoch 127/300\n",
      "269/269 [==============================] - 0s 133us/sample - loss: 8.1697 - mae: 2.0189 - val_loss: 14.6684 - val_mae: 2.8777\n",
      "Epoch 128/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 8.2155 - mae: 2.0272 - val_loss: 14.5787 - val_mae: 2.8604\n",
      "Epoch 129/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 8.1237 - mae: 2.0098 - val_loss: 14.5883 - val_mae: 2.8529\n",
      "Epoch 130/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 8.0820 - mae: 2.0033 - val_loss: 14.5681 - val_mae: 2.8501\n",
      "Epoch 131/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 7.9878 - mae: 1.9966 - val_loss: 14.5097 - val_mae: 2.8456\n",
      "Epoch 132/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 7.9991 - mae: 2.0062 - val_loss: 14.5026 - val_mae: 2.8457\n",
      "Epoch 133/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 7.9479 - mae: 2.0033 - val_loss: 14.5812 - val_mae: 2.8387\n",
      "Epoch 134/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 7.9308 - mae: 1.9930 - val_loss: 14.5957 - val_mae: 2.8617\n",
      "Epoch 135/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 7.8725 - mae: 2.0050 - val_loss: 14.5353 - val_mae: 2.8561\n",
      "Epoch 136/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 7.8115 - mae: 1.9876 - val_loss: 14.3214 - val_mae: 2.8216\n",
      "Epoch 137/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 7.7070 - mae: 1.9728 - val_loss: 14.4066 - val_mae: 2.8438\n",
      "Epoch 138/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 7.7146 - mae: 1.9895 - val_loss: 14.2534 - val_mae: 2.8191\n",
      "Epoch 139/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 7.6225 - mae: 1.9653 - val_loss: 14.2887 - val_mae: 2.8378\n",
      "Epoch 140/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 7.5496 - mae: 1.9480 - val_loss: 14.2017 - val_mae: 2.8174\n",
      "Epoch 141/300\n",
      "269/269 [==============================] - 0s 173us/sample - loss: 7.4832 - mae: 1.9429 - val_loss: 14.1601 - val_mae: 2.8187\n",
      "Epoch 142/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 7.4611 - mae: 1.9439 - val_loss: 14.2464 - val_mae: 2.8357\n",
      "Epoch 143/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 7.3847 - mae: 1.9351 - val_loss: 14.2494 - val_mae: 2.8338\n",
      "Epoch 144/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 7.4147 - mae: 1.9369 - val_loss: 14.1572 - val_mae: 2.8233\n",
      "Epoch 145/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 7.3036 - mae: 1.9151 - val_loss: 14.2735 - val_mae: 2.8239\n",
      "Epoch 146/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 7.3521 - mae: 1.9226 - val_loss: 14.3305 - val_mae: 2.8381\n",
      "Epoch 147/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 7.2934 - mae: 1.9361 - val_loss: 14.0633 - val_mae: 2.8072\n",
      "Epoch 148/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 7.2356 - mae: 1.9290 - val_loss: 14.0616 - val_mae: 2.8025\n",
      "Epoch 149/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 7.2500 - mae: 1.9326 - val_loss: 14.0485 - val_mae: 2.8155\n",
      "Epoch 150/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 7.0676 - mae: 1.9010 - val_loss: 13.9582 - val_mae: 2.7860\n",
      "Epoch 151/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 7.1053 - mae: 1.9009 - val_loss: 14.1194 - val_mae: 2.8144\n",
      "Epoch 152/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 7.0324 - mae: 1.8901 - val_loss: 13.9610 - val_mae: 2.7961\n",
      "Epoch 153/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 6.9877 - mae: 1.8935 - val_loss: 13.9889 - val_mae: 2.8115\n",
      "Epoch 154/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 6.9190 - mae: 1.8844 - val_loss: 13.9971 - val_mae: 2.8018\n",
      "Epoch 155/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 6.8736 - mae: 1.8704 - val_loss: 13.9463 - val_mae: 2.7978\n",
      "Epoch 156/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 6.7900 - mae: 1.8631 - val_loss: 13.9707 - val_mae: 2.8128\n",
      "Epoch 157/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 6.8313 - mae: 1.8757 - val_loss: 13.9480 - val_mae: 2.8099\n",
      "Epoch 158/300\n",
      "269/269 [==============================] - 0s 146us/sample - loss: 6.7004 - mae: 1.8549 - val_loss: 13.8449 - val_mae: 2.7798\n",
      "Epoch 159/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 6.7307 - mae: 1.8637 - val_loss: 13.8504 - val_mae: 2.7807\n",
      "Epoch 160/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 6.6383 - mae: 1.8522 - val_loss: 13.8924 - val_mae: 2.7942\n",
      "Epoch 161/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 6.6154 - mae: 1.8538 - val_loss: 13.9285 - val_mae: 2.8000\n",
      "Epoch 162/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 6.5856 - mae: 1.8398 - val_loss: 13.8616 - val_mae: 2.7866\n",
      "Epoch 163/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 6.5477 - mae: 1.8494 - val_loss: 13.8817 - val_mae: 2.8010\n",
      "Epoch 164/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 6.5155 - mae: 1.8357 - val_loss: 13.8763 - val_mae: 2.7955\n",
      "Epoch 165/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 6.4340 - mae: 1.8362 - val_loss: 14.0149 - val_mae: 2.8227\n",
      "Epoch 166/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 6.4220 - mae: 1.8349 - val_loss: 13.9631 - val_mae: 2.8040\n",
      "Epoch 167/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 6.3946 - mae: 1.8293 - val_loss: 13.9664 - val_mae: 2.7975\n",
      "Epoch 168/300\n",
      "269/269 [==============================] - 0s 146us/sample - loss: 6.3154 - mae: 1.8225 - val_loss: 13.9589 - val_mae: 2.7966\n",
      "Epoch 169/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 6.2978 - mae: 1.8204 - val_loss: 13.8729 - val_mae: 2.7946\n",
      "Epoch 170/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 6.2821 - mae: 1.8202 - val_loss: 13.7803 - val_mae: 2.7831\n",
      "Epoch 171/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 6.4144 - mae: 1.8228 - val_loss: 13.8596 - val_mae: 2.7804\n",
      "Epoch 172/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 6.2926 - mae: 1.8428 - val_loss: 13.8955 - val_mae: 2.8024\n",
      "Epoch 173/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 6.1792 - mae: 1.8178 - val_loss: 13.7494 - val_mae: 2.7750\n",
      "Epoch 174/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 6.1076 - mae: 1.8023 - val_loss: 13.7949 - val_mae: 2.7823\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 136us/sample - loss: 6.1137 - mae: 1.8034 - val_loss: 13.8027 - val_mae: 2.7935\n",
      "Epoch 176/300\n",
      "269/269 [==============================] - 0s 160us/sample - loss: 5.9859 - mae: 1.7864 - val_loss: 13.5191 - val_mae: 2.7516\n",
      "Epoch 177/300\n",
      "269/269 [==============================] - 0s 134us/sample - loss: 5.9968 - mae: 1.7814 - val_loss: 13.5173 - val_mae: 2.7532\n",
      "Epoch 178/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 5.9507 - mae: 1.7836 - val_loss: 13.6148 - val_mae: 2.7634\n",
      "Epoch 179/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 5.9535 - mae: 1.7887 - val_loss: 13.7437 - val_mae: 2.7806\n",
      "Epoch 180/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.9029 - mae: 1.7758 - val_loss: 13.6747 - val_mae: 2.7721\n",
      "Epoch 181/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.8807 - mae: 1.7701 - val_loss: 13.6084 - val_mae: 2.7595\n",
      "Epoch 182/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 5.8341 - mae: 1.7544 - val_loss: 13.6592 - val_mae: 2.7690\n",
      "Epoch 183/300\n",
      "269/269 [==============================] - 0s 134us/sample - loss: 5.8472 - mae: 1.7777 - val_loss: 13.8251 - val_mae: 2.7949\n",
      "Epoch 184/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 5.7877 - mae: 1.7661 - val_loss: 13.5532 - val_mae: 2.7547\n",
      "Epoch 185/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 5.7473 - mae: 1.7553 - val_loss: 13.5296 - val_mae: 2.7497\n",
      "Epoch 186/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.6864 - mae: 1.7479 - val_loss: 13.5577 - val_mae: 2.7588\n",
      "Epoch 187/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 5.6782 - mae: 1.7559 - val_loss: 13.6131 - val_mae: 2.7629\n",
      "Epoch 188/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 5.6188 - mae: 1.7423 - val_loss: 13.5952 - val_mae: 2.7554\n",
      "Epoch 189/300\n",
      "269/269 [==============================] - 0s 133us/sample - loss: 5.5907 - mae: 1.7284 - val_loss: 13.5854 - val_mae: 2.7528\n",
      "Epoch 190/300\n",
      "269/269 [==============================] - 0s 132us/sample - loss: 5.6141 - mae: 1.7394 - val_loss: 13.5785 - val_mae: 2.7532\n",
      "Epoch 191/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 5.5809 - mae: 1.7289 - val_loss: 13.4848 - val_mae: 2.7393\n",
      "Epoch 192/300\n",
      "269/269 [==============================] - 0s 134us/sample - loss: 5.6166 - mae: 1.7597 - val_loss: 13.6979 - val_mae: 2.7642\n",
      "Epoch 193/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 5.5622 - mae: 1.7426 - val_loss: 13.6947 - val_mae: 2.7756\n",
      "Epoch 194/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 5.4802 - mae: 1.7196 - val_loss: 13.4187 - val_mae: 2.7435\n",
      "Epoch 195/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.4278 - mae: 1.7157 - val_loss: 13.6340 - val_mae: 2.7690\n",
      "Epoch 196/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 5.3814 - mae: 1.7019 - val_loss: 13.3618 - val_mae: 2.7292\n",
      "Epoch 197/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 5.3637 - mae: 1.7010 - val_loss: 13.3622 - val_mae: 2.7351\n",
      "Epoch 198/300\n",
      "269/269 [==============================] - 0s 134us/sample - loss: 5.3341 - mae: 1.6998 - val_loss: 13.3259 - val_mae: 2.7291\n",
      "Epoch 199/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 5.3726 - mae: 1.7101 - val_loss: 13.4396 - val_mae: 2.7429\n",
      "Epoch 200/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.2756 - mae: 1.7080 - val_loss: 13.5088 - val_mae: 2.7517\n",
      "Epoch 201/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 5.2686 - mae: 1.6938 - val_loss: 13.3191 - val_mae: 2.7270\n",
      "Epoch 202/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 5.2487 - mae: 1.6867 - val_loss: 13.4590 - val_mae: 2.7440\n",
      "Epoch 203/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 5.1517 - mae: 1.6698 - val_loss: 13.4326 - val_mae: 2.7391\n",
      "Epoch 204/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 5.1651 - mae: 1.6828 - val_loss: 13.5032 - val_mae: 2.7516\n",
      "Epoch 205/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 5.1517 - mae: 1.6754 - val_loss: 13.4722 - val_mae: 2.7490\n",
      "Epoch 206/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 5.1073 - mae: 1.6713 - val_loss: 13.3006 - val_mae: 2.7158\n",
      "Epoch 207/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 5.0664 - mae: 1.6653 - val_loss: 13.4075 - val_mae: 2.7388\n",
      "Epoch 208/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.0471 - mae: 1.6674 - val_loss: 13.3695 - val_mae: 2.7213\n",
      "Epoch 209/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.1754 - mae: 1.6936 - val_loss: 13.1545 - val_mae: 2.7027\n",
      "Epoch 210/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 5.0093 - mae: 1.6512 - val_loss: 13.4237 - val_mae: 2.7437\n",
      "Epoch 211/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 4.9713 - mae: 1.6532 - val_loss: 13.3711 - val_mae: 2.7309\n",
      "Epoch 212/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.9514 - mae: 1.6509 - val_loss: 13.2831 - val_mae: 2.7256\n",
      "Epoch 213/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.9174 - mae: 1.6376 - val_loss: 13.1607 - val_mae: 2.7108\n",
      "Epoch 214/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 4.9152 - mae: 1.6309 - val_loss: 13.2815 - val_mae: 2.7228\n",
      "Epoch 215/300\n",
      "269/269 [==============================] - 0s 134us/sample - loss: 4.8642 - mae: 1.6371 - val_loss: 13.2543 - val_mae: 2.7246\n",
      "Epoch 216/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 4.8612 - mae: 1.6418 - val_loss: 13.2403 - val_mae: 2.7185\n",
      "Epoch 217/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 4.8046 - mae: 1.6236 - val_loss: 13.3611 - val_mae: 2.7265\n",
      "Epoch 218/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 4.7567 - mae: 1.6161 - val_loss: 13.4927 - val_mae: 2.7549\n",
      "Epoch 219/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 4.8641 - mae: 1.6446 - val_loss: 13.3217 - val_mae: 2.7356\n",
      "Epoch 220/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 4.7285 - mae: 1.6195 - val_loss: 13.1453 - val_mae: 2.7100\n",
      "Epoch 221/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.7588 - mae: 1.6213 - val_loss: 13.1563 - val_mae: 2.7049\n",
      "Epoch 222/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.7118 - mae: 1.6120 - val_loss: 13.4037 - val_mae: 2.7324\n",
      "Epoch 223/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.6585 - mae: 1.6001 - val_loss: 13.4139 - val_mae: 2.7418\n",
      "Epoch 224/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.6676 - mae: 1.6076 - val_loss: 13.2474 - val_mae: 2.7198\n",
      "Epoch 225/300\n",
      "269/269 [==============================] - 0s 134us/sample - loss: 4.6593 - mae: 1.6068 - val_loss: 13.2851 - val_mae: 2.7373\n",
      "Epoch 226/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.5665 - mae: 1.5788 - val_loss: 13.0321 - val_mae: 2.6997\n",
      "Epoch 227/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 4.5859 - mae: 1.5865 - val_loss: 13.2192 - val_mae: 2.7188\n",
      "Epoch 228/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.5571 - mae: 1.5956 - val_loss: 13.1803 - val_mae: 2.7076\n",
      "Epoch 229/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 4.5459 - mae: 1.5912 - val_loss: 13.2253 - val_mae: 2.7195\n",
      "Epoch 230/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 4.5340 - mae: 1.5844 - val_loss: 13.2012 - val_mae: 2.7069\n",
      "Epoch 231/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 4.4652 - mae: 1.5757 - val_loss: 13.3034 - val_mae: 2.7243\n",
      "Epoch 232/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 4.4368 - mae: 1.5779 - val_loss: 13.1919 - val_mae: 2.7133\n",
      "Epoch 233/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.4942 - mae: 1.5806 - val_loss: 13.2111 - val_mae: 2.7058\n",
      "Epoch 234/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 4.5151 - mae: 1.5835 - val_loss: 13.1411 - val_mae: 2.6878\n",
      "Epoch 235/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 4.4151 - mae: 1.5621 - val_loss: 13.2663 - val_mae: 2.7153\n",
      "Epoch 236/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.4217 - mae: 1.5790 - val_loss: 13.0513 - val_mae: 2.6848\n",
      "Epoch 237/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.4909 - mae: 1.5780 - val_loss: 13.0547 - val_mae: 2.6853\n",
      "Epoch 238/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.3577 - mae: 1.5642 - val_loss: 13.1260 - val_mae: 2.6971\n",
      "Epoch 239/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 4.3017 - mae: 1.5517 - val_loss: 12.9336 - val_mae: 2.6837\n",
      "Epoch 240/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 4.2930 - mae: 1.5375 - val_loss: 12.9779 - val_mae: 2.6864\n",
      "Epoch 241/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.2992 - mae: 1.5527 - val_loss: 13.0699 - val_mae: 2.6950\n",
      "Epoch 242/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.2622 - mae: 1.5368 - val_loss: 12.8402 - val_mae: 2.6687\n",
      "Epoch 243/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.2045 - mae: 1.5298 - val_loss: 12.8603 - val_mae: 2.6746\n",
      "Epoch 244/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.2207 - mae: 1.5390 - val_loss: 12.9816 - val_mae: 2.6836\n",
      "Epoch 245/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.1658 - mae: 1.5126 - val_loss: 12.9079 - val_mae: 2.6657\n",
      "Epoch 246/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 4.1937 - mae: 1.5175 - val_loss: 13.0075 - val_mae: 2.6728\n",
      "Epoch 247/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 4.1146 - mae: 1.5199 - val_loss: 13.0390 - val_mae: 2.6743\n",
      "Epoch 248/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 4.1232 - mae: 1.5261 - val_loss: 12.8444 - val_mae: 2.6661\n",
      "Epoch 249/300\n",
      "269/269 [==============================] - 0s 156us/sample - loss: 4.1438 - mae: 1.5154 - val_loss: 12.7745 - val_mae: 2.6487\n",
      "Epoch 250/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 4.0529 - mae: 1.4955 - val_loss: 12.8961 - val_mae: 2.6594\n",
      "Epoch 251/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.1258 - mae: 1.5282 - val_loss: 12.9670 - val_mae: 2.6754\n",
      "Epoch 252/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 4.0010 - mae: 1.4937 - val_loss: 12.7609 - val_mae: 2.6424\n",
      "Epoch 253/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 4.0615 - mae: 1.5021 - val_loss: 13.0142 - val_mae: 2.6747\n",
      "Epoch 254/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.9550 - mae: 1.4934 - val_loss: 12.9529 - val_mae: 2.6675\n",
      "Epoch 255/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 4.0060 - mae: 1.4902 - val_loss: 12.8639 - val_mae: 2.6603\n",
      "Epoch 256/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 3.9804 - mae: 1.4855 - val_loss: 12.8500 - val_mae: 2.6604\n",
      "Epoch 257/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.9216 - mae: 1.4790 - val_loss: 12.8577 - val_mae: 2.6582\n",
      "Epoch 258/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 3.8967 - mae: 1.4722 - val_loss: 13.0268 - val_mae: 2.6850\n",
      "Epoch 259/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.9405 - mae: 1.4695 - val_loss: 12.7830 - val_mae: 2.6413\n",
      "Epoch 260/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 3.9434 - mae: 1.4811 - val_loss: 12.9038 - val_mae: 2.6732\n",
      "Epoch 261/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 3.8642 - mae: 1.4591 - val_loss: 12.7430 - val_mae: 2.6454\n",
      "Epoch 262/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 3.8076 - mae: 1.4581 - val_loss: 12.8638 - val_mae: 2.6547\n",
      "Epoch 263/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 3.8792 - mae: 1.4809 - val_loss: 12.7935 - val_mae: 2.6525\n",
      "Epoch 264/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 3.8396 - mae: 1.4638 - val_loss: 12.8533 - val_mae: 2.6605\n",
      "Epoch 265/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 3.7857 - mae: 1.4579 - val_loss: 12.9549 - val_mae: 2.6717\n",
      "Epoch 266/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 3.8034 - mae: 1.4605 - val_loss: 12.7992 - val_mae: 2.6471\n",
      "Epoch 267/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 3.7677 - mae: 1.4602 - val_loss: 12.8870 - val_mae: 2.6498\n",
      "Epoch 268/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 3.7570 - mae: 1.4578 - val_loss: 12.8378 - val_mae: 2.6488\n",
      "Epoch 269/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.7194 - mae: 1.4387 - val_loss: 12.6456 - val_mae: 2.6242\n",
      "Epoch 270/300\n",
      "269/269 [==============================] - 0s 144us/sample - loss: 3.7263 - mae: 1.4507 - val_loss: 12.9227 - val_mae: 2.6593\n",
      "Epoch 271/300\n",
      "269/269 [==============================] - 0s 145us/sample - loss: 3.7381 - mae: 1.4440 - val_loss: 12.8509 - val_mae: 2.6503\n",
      "Epoch 272/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.7446 - mae: 1.4515 - val_loss: 12.6793 - val_mae: 2.6329\n",
      "Epoch 273/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.6693 - mae: 1.4311 - val_loss: 12.8635 - val_mae: 2.6574\n",
      "Epoch 274/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 3.6482 - mae: 1.4205 - val_loss: 12.7963 - val_mae: 2.6489\n",
      "Epoch 275/300\n",
      "269/269 [==============================] - 0s 144us/sample - loss: 3.7327 - mae: 1.4497 - val_loss: 12.7010 - val_mae: 2.6216\n",
      "Epoch 276/300\n",
      "269/269 [==============================] - 0s 144us/sample - loss: 3.6772 - mae: 1.4299 - val_loss: 12.9687 - val_mae: 2.6683\n",
      "Epoch 277/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.6396 - mae: 1.4334 - val_loss: 12.6071 - val_mae: 2.6179\n",
      "Epoch 278/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.5928 - mae: 1.4159 - val_loss: 12.7433 - val_mae: 2.6354\n",
      "Epoch 279/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 3.5476 - mae: 1.4052 - val_loss: 12.6891 - val_mae: 2.6220\n",
      "Epoch 280/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 3.5755 - mae: 1.4084 - val_loss: 12.7123 - val_mae: 2.6329\n",
      "Epoch 281/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 3.5516 - mae: 1.4156 - val_loss: 12.7798 - val_mae: 2.6392\n",
      "Epoch 282/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.5494 - mae: 1.4103 - val_loss: 12.7058 - val_mae: 2.6207\n",
      "Epoch 283/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.5900 - mae: 1.4229 - val_loss: 12.4165 - val_mae: 2.5845\n",
      "Epoch 284/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.5729 - mae: 1.4110 - val_loss: 12.5319 - val_mae: 2.6042\n",
      "Epoch 285/300\n",
      "269/269 [==============================] - 0s 145us/sample - loss: 3.5054 - mae: 1.3933 - val_loss: 12.6576 - val_mae: 2.6187\n",
      "Epoch 286/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 3.4734 - mae: 1.3947 - val_loss: 12.6327 - val_mae: 2.6114\n",
      "Epoch 287/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 3.4883 - mae: 1.3972 - val_loss: 12.6326 - val_mae: 2.6140\n",
      "Epoch 288/300\n",
      "269/269 [==============================] - 0s 153us/sample - loss: 3.4889 - mae: 1.3881 - val_loss: 12.5414 - val_mae: 2.6148\n",
      "Epoch 289/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 3.5359 - mae: 1.3854 - val_loss: 12.4223 - val_mae: 2.5716\n",
      "Epoch 290/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.4183 - mae: 1.3760 - val_loss: 12.6972 - val_mae: 2.6098\n",
      "Epoch 291/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 141us/sample - loss: 3.4038 - mae: 1.3787 - val_loss: 12.5333 - val_mae: 2.5899\n",
      "Epoch 292/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.3879 - mae: 1.3702 - val_loss: 12.6187 - val_mae: 2.5989\n",
      "Epoch 293/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.3923 - mae: 1.3693 - val_loss: 12.6597 - val_mae: 2.6219\n",
      "Epoch 294/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 3.3992 - mae: 1.3690 - val_loss: 12.3874 - val_mae: 2.5689\n",
      "Epoch 295/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 3.3360 - mae: 1.3632 - val_loss: 12.6141 - val_mae: 2.6056\n",
      "Epoch 296/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 3.3792 - mae: 1.3663 - val_loss: 12.7447 - val_mae: 2.6102\n",
      "Epoch 297/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 3.3735 - mae: 1.3745 - val_loss: 12.4875 - val_mae: 2.5894\n",
      "Epoch 298/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 3.3309 - mae: 1.3614 - val_loss: 12.4420 - val_mae: 2.5811\n",
      "Epoch 299/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.2869 - mae: 1.3558 - val_loss: 12.6349 - val_mae: 2.6073\n",
      "Epoch 300/300\n",
      "269/269 [==============================] - 0s 158us/sample - loss: 3.2869 - mae: 1.3514 - val_loss: 12.5767 - val_mae: 2.6044\n",
      "102/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 65us/sample - loss: 5.9660 - mae: 2.0574\n",
      "Train on 269 samples, validate on 135 samples\n",
      "Epoch 1/300\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 499.9922 - mae: 20.4441 - val_loss: 582.4945 - val_mae: 22.1305\n",
      "Epoch 2/300\n",
      "269/269 [==============================] - 0s 147us/sample - loss: 467.8066 - mae: 19.6021 - val_loss: 542.5106 - val_mae: 21.2150\n",
      "Epoch 3/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 430.8455 - mae: 18.6134 - val_loss: 495.7208 - val_mae: 20.1170\n",
      "Epoch 4/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 388.1047 - mae: 17.4206 - val_loss: 440.5284 - val_mae: 18.7618\n",
      "Epoch 5/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 339.1938 - mae: 15.9965 - val_loss: 377.1484 - val_mae: 17.1251\n",
      "Epoch 6/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 286.6105 - mae: 14.4352 - val_loss: 309.9217 - val_mae: 15.2491\n",
      "Epoch 7/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 231.6573 - mae: 12.7313 - val_loss: 242.5392 - val_mae: 13.1030\n",
      "Epoch 8/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 180.5008 - mae: 10.9423 - val_loss: 183.4539 - val_mae: 10.9173\n",
      "Epoch 9/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 136.9134 - mae: 9.2556 - val_loss: 138.1135 - val_mae: 8.9234\n",
      "Epoch 10/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 105.8575 - mae: 7.9944 - val_loss: 108.9117 - val_mae: 7.8421\n",
      "Epoch 11/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 83.8973 - mae: 7.0599 - val_loss: 91.3540 - val_mae: 7.2154\n",
      "Epoch 12/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 68.6410 - mae: 6.3110 - val_loss: 78.4800 - val_mae: 6.6585\n",
      "Epoch 13/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 56.8916 - mae: 5.6756 - val_loss: 67.2899 - val_mae: 6.0512\n",
      "Epoch 14/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 47.9013 - mae: 5.1147 - val_loss: 57.7749 - val_mae: 5.4442\n",
      "Epoch 15/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 40.0017 - mae: 4.6416 - val_loss: 50.7551 - val_mae: 4.9896\n",
      "Epoch 16/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 34.7567 - mae: 4.3141 - val_loss: 45.5593 - val_mae: 4.6485\n",
      "Epoch 17/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 30.8429 - mae: 4.0610 - val_loss: 42.1709 - val_mae: 4.4017\n",
      "Epoch 18/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 28.3620 - mae: 3.8967 - val_loss: 39.1018 - val_mae: 4.2170\n",
      "Epoch 19/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 26.4370 - mae: 3.7577 - val_loss: 37.2089 - val_mae: 4.0748\n",
      "Epoch 20/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 24.9191 - mae: 3.6342 - val_loss: 35.7497 - val_mae: 3.9663\n",
      "Epoch 21/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 23.8578 - mae: 3.5455 - val_loss: 34.1600 - val_mae: 3.8773\n",
      "Epoch 22/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 22.9241 - mae: 3.4827 - val_loss: 32.9442 - val_mae: 3.8065\n",
      "Epoch 23/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 21.9829 - mae: 3.4045 - val_loss: 32.0984 - val_mae: 3.7380\n",
      "Epoch 24/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 21.3240 - mae: 3.3445 - val_loss: 31.2239 - val_mae: 3.6729\n",
      "Epoch 25/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 20.5998 - mae: 3.2825 - val_loss: 30.5469 - val_mae: 3.6213\n",
      "Epoch 26/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 20.0296 - mae: 3.2397 - val_loss: 29.7779 - val_mae: 3.5807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 19.4953 - mae: 3.1968 - val_loss: 29.0557 - val_mae: 3.5228\n",
      "Epoch 28/300\n",
      "269/269 [==============================] - 0s 134us/sample - loss: 18.9027 - mae: 3.1495 - val_loss: 28.5478 - val_mae: 3.4613\n",
      "Epoch 29/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 18.3748 - mae: 3.0957 - val_loss: 28.0077 - val_mae: 3.3946\n",
      "Epoch 30/300\n",
      "269/269 [==============================] - 0s 134us/sample - loss: 17.8761 - mae: 3.0448 - val_loss: 27.5884 - val_mae: 3.3470\n",
      "Epoch 31/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 17.4570 - mae: 2.9941 - val_loss: 27.2335 - val_mae: 3.3195\n",
      "Epoch 32/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 17.0733 - mae: 2.9588 - val_loss: 26.6831 - val_mae: 3.2848\n",
      "Epoch 33/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 16.6381 - mae: 2.9297 - val_loss: 26.1854 - val_mae: 3.2659\n",
      "Epoch 34/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 16.2991 - mae: 2.8986 - val_loss: 25.8425 - val_mae: 3.2358\n",
      "Epoch 35/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 15.9179 - mae: 2.8611 - val_loss: 25.5007 - val_mae: 3.2181\n",
      "Epoch 36/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 15.6277 - mae: 2.8450 - val_loss: 25.0098 - val_mae: 3.2034\n",
      "Epoch 37/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 15.2493 - mae: 2.7959 - val_loss: 24.8237 - val_mae: 3.1527\n",
      "Epoch 38/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 14.9540 - mae: 2.7532 - val_loss: 24.5482 - val_mae: 3.1399\n",
      "Epoch 39/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 14.6754 - mae: 2.7184 - val_loss: 24.3491 - val_mae: 3.1190\n",
      "Epoch 40/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 14.3979 - mae: 2.6908 - val_loss: 24.0488 - val_mae: 3.1044\n",
      "Epoch 41/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 14.1667 - mae: 2.6728 - val_loss: 23.7711 - val_mae: 3.1240\n",
      "Epoch 42/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 13.8363 - mae: 2.6439 - val_loss: 23.5487 - val_mae: 3.0981\n",
      "Epoch 43/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 13.6328 - mae: 2.6104 - val_loss: 23.3498 - val_mae: 3.0766\n",
      "Epoch 44/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 13.3717 - mae: 2.5799 - val_loss: 23.0764 - val_mae: 3.0499\n",
      "Epoch 45/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 13.1654 - mae: 2.5626 - val_loss: 22.8894 - val_mae: 3.0402\n",
      "Epoch 46/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 12.8975 - mae: 2.5345 - val_loss: 22.7180 - val_mae: 3.0536\n",
      "Epoch 47/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 12.7189 - mae: 2.5187 - val_loss: 22.4747 - val_mae: 3.0302\n",
      "Epoch 48/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 12.5227 - mae: 2.4962 - val_loss: 22.2851 - val_mae: 3.0086\n",
      "Epoch 49/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 12.3296 - mae: 2.4682 - val_loss: 22.1502 - val_mae: 2.9971\n",
      "Epoch 50/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 12.1736 - mae: 2.4493 - val_loss: 21.9980 - val_mae: 2.9738\n",
      "Epoch 51/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 11.9985 - mae: 2.4367 - val_loss: 21.7338 - val_mae: 2.9588\n",
      "Epoch 52/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 11.7822 - mae: 2.4273 - val_loss: 21.5550 - val_mae: 2.9554\n",
      "Epoch 53/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 11.7378 - mae: 2.4034 - val_loss: 21.4766 - val_mae: 2.9319\n",
      "Epoch 54/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 11.5418 - mae: 2.4117 - val_loss: 21.2792 - val_mae: 2.9599\n",
      "Epoch 55/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 11.3342 - mae: 2.3935 - val_loss: 21.2298 - val_mae: 2.9333\n",
      "Epoch 56/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 11.1232 - mae: 2.3518 - val_loss: 21.1451 - val_mae: 2.9112\n",
      "Epoch 57/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 10.9872 - mae: 2.3304 - val_loss: 20.9150 - val_mae: 2.8737\n",
      "Epoch 58/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 10.8391 - mae: 2.3250 - val_loss: 20.8547 - val_mae: 2.8853\n",
      "Epoch 59/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 10.8534 - mae: 2.3443 - val_loss: 20.7539 - val_mae: 2.9062\n",
      "Epoch 60/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 10.5688 - mae: 2.3098 - val_loss: 20.7422 - val_mae: 2.8856\n",
      "Epoch 61/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 10.4655 - mae: 2.2816 - val_loss: 20.6185 - val_mae: 2.8500\n",
      "Epoch 62/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 10.3977 - mae: 2.2641 - val_loss: 20.6280 - val_mae: 2.8659\n",
      "Epoch 63/300\n",
      "269/269 [==============================] - 0s 144us/sample - loss: 10.2129 - mae: 2.2570 - val_loss: 20.5519 - val_mae: 2.8838\n",
      "Epoch 64/300\n",
      "269/269 [==============================] - 0s 144us/sample - loss: 10.1713 - mae: 2.2872 - val_loss: 20.4730 - val_mae: 2.8705\n",
      "Epoch 65/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 10.0595 - mae: 2.2480 - val_loss: 20.4220 - val_mae: 2.8291\n",
      "Epoch 66/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 9.9675 - mae: 2.2305 - val_loss: 20.3078 - val_mae: 2.8404\n",
      "Epoch 67/300\n",
      "269/269 [==============================] - 0s 145us/sample - loss: 9.8515 - mae: 2.2164 - val_loss: 20.2512 - val_mae: 2.8284\n",
      "Epoch 68/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 9.6872 - mae: 2.1964 - val_loss: 20.2298 - val_mae: 2.8410\n",
      "Epoch 69/300\n",
      "269/269 [==============================] - 0s 144us/sample - loss: 9.6524 - mae: 2.2158 - val_loss: 20.1032 - val_mae: 2.8360\n",
      "Epoch 70/300\n",
      "269/269 [==============================] - 0s 144us/sample - loss: 9.5172 - mae: 2.1949 - val_loss: 20.0332 - val_mae: 2.8199\n",
      "Epoch 71/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 9.4643 - mae: 2.1496 - val_loss: 20.0989 - val_mae: 2.8161\n",
      "Epoch 72/300\n",
      "269/269 [==============================] - 0s 144us/sample - loss: 9.4009 - mae: 2.1490 - val_loss: 20.1074 - val_mae: 2.8353\n",
      "Epoch 73/300\n",
      "269/269 [==============================] - 0s 145us/sample - loss: 9.2875 - mae: 2.1652 - val_loss: 20.0447 - val_mae: 2.8261\n",
      "Epoch 74/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 9.2125 - mae: 2.1529 - val_loss: 19.8873 - val_mae: 2.7806\n",
      "Epoch 75/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 9.1345 - mae: 2.1374 - val_loss: 19.8599 - val_mae: 2.7871\n",
      "Epoch 76/300\n",
      "269/269 [==============================] - 0s 144us/sample - loss: 9.0749 - mae: 2.1427 - val_loss: 19.8551 - val_mae: 2.8201\n",
      "Epoch 77/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 9.0425 - mae: 2.1583 - val_loss: 19.9046 - val_mae: 2.8436\n",
      "Epoch 78/300\n",
      "269/269 [==============================] - 0s 145us/sample - loss: 8.9379 - mae: 2.1087 - val_loss: 19.7640 - val_mae: 2.7874\n",
      "Epoch 79/300\n",
      "269/269 [==============================] - 0s 144us/sample - loss: 8.8600 - mae: 2.0896 - val_loss: 19.6459 - val_mae: 2.7778\n",
      "Epoch 80/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 8.7222 - mae: 2.0800 - val_loss: 19.6814 - val_mae: 2.8015\n",
      "Epoch 81/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 8.6525 - mae: 2.0728 - val_loss: 19.6476 - val_mae: 2.8061\n",
      "Epoch 82/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 8.6378 - mae: 2.0870 - val_loss: 19.4019 - val_mae: 2.7598\n",
      "Epoch 83/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 8.6045 - mae: 2.0851 - val_loss: 19.4809 - val_mae: 2.7728\n",
      "Epoch 84/300\n",
      "269/269 [==============================] - 0s 144us/sample - loss: 8.5098 - mae: 2.0404 - val_loss: 19.5412 - val_mae: 2.7752\n",
      "Epoch 85/300\n",
      "269/269 [==============================] - 0s 144us/sample - loss: 8.4018 - mae: 2.0221 - val_loss: 19.4619 - val_mae: 2.7582\n",
      "Epoch 86/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 8.4267 - mae: 2.0588 - val_loss: 19.4893 - val_mae: 2.7833\n",
      "Epoch 87/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 8.2731 - mae: 2.0279 - val_loss: 19.4631 - val_mae: 2.7590\n",
      "Epoch 88/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 8.2554 - mae: 2.0094 - val_loss: 19.3275 - val_mae: 2.7381\n",
      "Epoch 89/300\n",
      "269/269 [==============================] - 0s 144us/sample - loss: 8.1860 - mae: 2.0099 - val_loss: 19.4227 - val_mae: 2.7573\n",
      "Epoch 90/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 8.1062 - mae: 2.0024 - val_loss: 19.4780 - val_mae: 2.7758\n",
      "Epoch 91/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 8.0875 - mae: 1.9957 - val_loss: 19.4250 - val_mae: 2.7763\n",
      "Epoch 92/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 8.0143 - mae: 1.9882 - val_loss: 19.2801 - val_mae: 2.7451\n",
      "Epoch 93/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 7.9485 - mae: 1.9791 - val_loss: 19.3472 - val_mae: 2.7599\n",
      "Epoch 94/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 7.9323 - mae: 1.9700 - val_loss: 19.4504 - val_mae: 2.7865\n",
      "Epoch 95/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 7.8805 - mae: 1.9643 - val_loss: 19.3836 - val_mae: 2.7518\n",
      "Epoch 96/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 7.8114 - mae: 1.9582 - val_loss: 19.2815 - val_mae: 2.7434\n",
      "Epoch 97/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 7.7866 - mae: 1.9645 - val_loss: 19.3549 - val_mae: 2.7556\n",
      "Epoch 98/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 7.7428 - mae: 1.9459 - val_loss: 19.3904 - val_mae: 2.7650\n",
      "Epoch 99/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 7.7151 - mae: 1.9339 - val_loss: 19.2060 - val_mae: 2.7335\n",
      "Epoch 100/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 7.6692 - mae: 1.9418 - val_loss: 19.2448 - val_mae: 2.7578\n",
      "Epoch 101/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 7.5800 - mae: 1.9386 - val_loss: 19.2294 - val_mae: 2.7578\n",
      "Epoch 102/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 7.5505 - mae: 1.9042 - val_loss: 19.2079 - val_mae: 2.7261\n",
      "Epoch 103/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 7.4990 - mae: 1.9014 - val_loss: 19.2471 - val_mae: 2.7454\n",
      "Epoch 104/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 7.5352 - mae: 1.9409 - val_loss: 19.4039 - val_mae: 2.7984\n",
      "Epoch 105/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 7.4111 - mae: 1.9191 - val_loss: 19.2148 - val_mae: 2.7351\n",
      "Epoch 106/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 7.4196 - mae: 1.8967 - val_loss: 19.2565 - val_mae: 2.7527\n",
      "Epoch 107/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 7.3482 - mae: 1.8847 - val_loss: 19.1044 - val_mae: 2.7241\n",
      "Epoch 108/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 7.2566 - mae: 1.8943 - val_loss: 19.1494 - val_mae: 2.7623\n",
      "Epoch 109/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 7.2230 - mae: 1.8857 - val_loss: 19.1949 - val_mae: 2.7418\n",
      "Epoch 110/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 7.2215 - mae: 1.8671 - val_loss: 18.9933 - val_mae: 2.7152\n",
      "Epoch 111/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 7.1363 - mae: 1.8591 - val_loss: 19.0309 - val_mae: 2.7394\n",
      "Epoch 112/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 7.1073 - mae: 1.8645 - val_loss: 19.1090 - val_mae: 2.7652\n",
      "Epoch 113/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 7.1138 - mae: 1.8548 - val_loss: 18.9752 - val_mae: 2.7309\n",
      "Epoch 114/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 7.0658 - mae: 1.8557 - val_loss: 19.2588 - val_mae: 2.7861\n",
      "Epoch 115/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 6.9611 - mae: 1.8342 - val_loss: 19.1094 - val_mae: 2.7500\n",
      "Epoch 116/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 6.9564 - mae: 1.8315 - val_loss: 18.9707 - val_mae: 2.7354\n",
      "Epoch 117/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 6.9322 - mae: 1.8319 - val_loss: 19.0382 - val_mae: 2.7713\n",
      "Epoch 118/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 6.8586 - mae: 1.8159 - val_loss: 18.9472 - val_mae: 2.7333\n",
      "Epoch 119/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 6.8794 - mae: 1.8153 - val_loss: 18.9383 - val_mae: 2.7425\n",
      "Epoch 120/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 6.7821 - mae: 1.8509 - val_loss: 19.1884 - val_mae: 2.8165\n",
      "Epoch 121/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 6.9000 - mae: 1.8192 - val_loss: 18.9534 - val_mae: 2.7338\n",
      "Epoch 122/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 6.6866 - mae: 1.7905 - val_loss: 18.9536 - val_mae: 2.7424\n",
      "Epoch 123/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 6.7680 - mae: 1.8293 - val_loss: 19.0524 - val_mae: 2.7772\n",
      "Epoch 124/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 6.6124 - mae: 1.7881 - val_loss: 19.0035 - val_mae: 2.7464\n",
      "Epoch 125/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 6.5985 - mae: 1.7690 - val_loss: 18.8566 - val_mae: 2.7386\n",
      "Epoch 126/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 6.5318 - mae: 1.7718 - val_loss: 18.7424 - val_mae: 2.7313\n",
      "Epoch 127/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 6.5141 - mae: 1.7729 - val_loss: 18.8127 - val_mae: 2.7400\n",
      "Epoch 128/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 6.4639 - mae: 1.7594 - val_loss: 18.8167 - val_mae: 2.7300\n",
      "Epoch 129/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 6.4443 - mae: 1.7597 - val_loss: 18.8853 - val_mae: 2.7217\n",
      "Epoch 130/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 6.4203 - mae: 1.7595 - val_loss: 18.8852 - val_mae: 2.7480\n",
      "Epoch 131/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 6.3739 - mae: 1.7462 - val_loss: 18.8005 - val_mae: 2.7244\n",
      "Epoch 132/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 6.4082 - mae: 1.7503 - val_loss: 18.7863 - val_mae: 2.7497\n",
      "Epoch 133/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 6.3381 - mae: 1.7434 - val_loss: 18.6755 - val_mae: 2.7147\n",
      "Epoch 134/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 6.2974 - mae: 1.7396 - val_loss: 18.6859 - val_mae: 2.7369\n",
      "Epoch 135/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 6.3529 - mae: 1.7349 - val_loss: 18.7606 - val_mae: 2.7355\n",
      "Epoch 136/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 6.5199 - mae: 1.7870 - val_loss: 18.8711 - val_mae: 2.7760\n",
      "Epoch 137/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 6.2087 - mae: 1.7427 - val_loss: 18.6851 - val_mae: 2.7066\n",
      "Epoch 138/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 6.3223 - mae: 1.7181 - val_loss: 18.6958 - val_mae: 2.7487\n",
      "Epoch 139/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 6.1192 - mae: 1.7089 - val_loss: 18.7169 - val_mae: 2.7712\n",
      "Epoch 140/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 6.1775 - mae: 1.7488 - val_loss: 18.7448 - val_mae: 2.7544\n",
      "Epoch 141/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 6.1964 - mae: 1.7163 - val_loss: 18.7403 - val_mae: 2.7180\n",
      "Epoch 142/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 6.1130 - mae: 1.7141 - val_loss: 18.8161 - val_mae: 2.7746\n",
      "Epoch 143/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 5.9941 - mae: 1.6975 - val_loss: 18.7299 - val_mae: 2.7355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 6.0433 - mae: 1.7029 - val_loss: 18.5807 - val_mae: 2.7135\n",
      "Epoch 145/300\n",
      "269/269 [==============================] - 0s 134us/sample - loss: 5.9194 - mae: 1.6855 - val_loss: 18.7068 - val_mae: 2.7562\n",
      "Epoch 146/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.9313 - mae: 1.6872 - val_loss: 18.8040 - val_mae: 2.7431\n",
      "Epoch 147/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 5.8750 - mae: 1.6712 - val_loss: 18.8150 - val_mae: 2.7451\n",
      "Epoch 148/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.8876 - mae: 1.6675 - val_loss: 18.8314 - val_mae: 2.7395\n",
      "Epoch 149/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 5.8518 - mae: 1.6635 - val_loss: 18.7908 - val_mae: 2.7605\n",
      "Epoch 150/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 5.9529 - mae: 1.6700 - val_loss: 18.9150 - val_mae: 2.7638\n",
      "Epoch 151/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.8678 - mae: 1.6810 - val_loss: 18.7997 - val_mae: 2.7489\n",
      "Epoch 152/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 5.8219 - mae: 1.6837 - val_loss: 18.6427 - val_mae: 2.7178\n",
      "Epoch 153/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 5.6964 - mae: 1.6397 - val_loss: 18.8551 - val_mae: 2.7594\n",
      "Epoch 154/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 5.7167 - mae: 1.6426 - val_loss: 18.6621 - val_mae: 2.7398\n",
      "Epoch 155/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 5.6748 - mae: 1.6314 - val_loss: 18.6680 - val_mae: 2.7362\n",
      "Epoch 156/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.6797 - mae: 1.6313 - val_loss: 18.8151 - val_mae: 2.7498\n",
      "Epoch 157/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 5.7653 - mae: 1.6504 - val_loss: 18.9305 - val_mae: 2.7367\n",
      "Epoch 158/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.5569 - mae: 1.6098 - val_loss: 18.7551 - val_mae: 2.7418\n",
      "Epoch 159/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 5.7616 - mae: 1.6268 - val_loss: 18.4868 - val_mae: 2.7059\n",
      "Epoch 160/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 5.4899 - mae: 1.6098 - val_loss: 18.6521 - val_mae: 2.7561\n",
      "Epoch 161/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 5.6522 - mae: 1.6614 - val_loss: 18.6318 - val_mae: 2.7242\n",
      "Epoch 162/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 5.6369 - mae: 1.6107 - val_loss: 18.7933 - val_mae: 2.7322\n",
      "Epoch 163/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 5.5361 - mae: 1.6265 - val_loss: 18.8640 - val_mae: 2.7893\n",
      "Epoch 164/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 5.4784 - mae: 1.6307 - val_loss: 18.5933 - val_mae: 2.7226\n",
      "Epoch 165/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 5.5392 - mae: 1.6156 - val_loss: 18.7075 - val_mae: 2.7528\n",
      "Epoch 166/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 5.4024 - mae: 1.6096 - val_loss: 18.6075 - val_mae: 2.7420\n",
      "Epoch 167/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 5.4169 - mae: 1.6160 - val_loss: 18.6342 - val_mae: 2.7560\n",
      "Epoch 168/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 5.3398 - mae: 1.5831 - val_loss: 18.5512 - val_mae: 2.7136\n",
      "Epoch 169/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.3171 - mae: 1.5772 - val_loss: 18.5193 - val_mae: 2.7394\n",
      "Epoch 170/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 5.3884 - mae: 1.6095 - val_loss: 18.4552 - val_mae: 2.7255\n",
      "Epoch 171/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.2597 - mae: 1.5772 - val_loss: 18.3817 - val_mae: 2.6829\n",
      "Epoch 172/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 5.3315 - mae: 1.5661 - val_loss: 18.4995 - val_mae: 2.7226\n",
      "Epoch 173/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 5.2391 - mae: 1.5685 - val_loss: 18.2690 - val_mae: 2.6861\n",
      "Epoch 174/300\n",
      "269/269 [==============================] - 0s 134us/sample - loss: 5.2555 - mae: 1.5595 - val_loss: 18.3203 - val_mae: 2.7017\n",
      "Epoch 175/300\n",
      "269/269 [==============================] - 0s 134us/sample - loss: 5.1610 - mae: 1.5540 - val_loss: 18.4045 - val_mae: 2.7280\n",
      "Epoch 176/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 5.1629 - mae: 1.5582 - val_loss: 18.3702 - val_mae: 2.7096\n",
      "Epoch 177/300\n",
      "269/269 [==============================] - 0s 134us/sample - loss: 5.1361 - mae: 1.5401 - val_loss: 18.4467 - val_mae: 2.7028\n",
      "Epoch 178/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 5.1878 - mae: 1.5581 - val_loss: 18.6639 - val_mae: 2.7529\n",
      "Epoch 179/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.1294 - mae: 1.5437 - val_loss: 18.4349 - val_mae: 2.7012\n",
      "Epoch 180/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.0594 - mae: 1.5348 - val_loss: 18.4156 - val_mae: 2.7219\n",
      "Epoch 181/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 5.0681 - mae: 1.5474 - val_loss: 18.4278 - val_mae: 2.7249\n",
      "Epoch 182/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.9984 - mae: 1.5265 - val_loss: 18.3542 - val_mae: 2.7002\n",
      "Epoch 183/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.0436 - mae: 1.5199 - val_loss: 18.2596 - val_mae: 2.7107\n",
      "Epoch 184/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.9678 - mae: 1.5282 - val_loss: 18.1417 - val_mae: 2.6860\n",
      "Epoch 185/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 5.1052 - mae: 1.5285 - val_loss: 18.2866 - val_mae: 2.7033\n",
      "Epoch 186/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 4.9346 - mae: 1.5240 - val_loss: 18.3955 - val_mae: 2.7283\n",
      "Epoch 187/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 5.0792 - mae: 1.5680 - val_loss: 18.4066 - val_mae: 2.7116\n",
      "Epoch 188/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.9345 - mae: 1.5184 - val_loss: 18.5057 - val_mae: 2.7349\n",
      "Epoch 189/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.8873 - mae: 1.4964 - val_loss: 18.4250 - val_mae: 2.7288\n",
      "Epoch 190/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.8865 - mae: 1.5319 - val_loss: 18.2450 - val_mae: 2.7082\n",
      "Epoch 191/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.9128 - mae: 1.4948 - val_loss: 18.3490 - val_mae: 2.7271\n",
      "Epoch 192/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.8547 - mae: 1.5131 - val_loss: 18.0979 - val_mae: 2.6817\n",
      "Epoch 193/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.8081 - mae: 1.5128 - val_loss: 18.1922 - val_mae: 2.6928\n",
      "Epoch 194/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.8895 - mae: 1.4756 - val_loss: 18.1980 - val_mae: 2.6929\n",
      "Epoch 195/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.8277 - mae: 1.5038 - val_loss: 18.3429 - val_mae: 2.7412\n",
      "Epoch 196/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 4.7550 - mae: 1.4981 - val_loss: 18.1926 - val_mae: 2.6890\n",
      "Epoch 197/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.8028 - mae: 1.4648 - val_loss: 18.1375 - val_mae: 2.6937\n",
      "Epoch 198/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.6539 - mae: 1.4646 - val_loss: 18.3232 - val_mae: 2.7426\n",
      "Epoch 199/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 4.7697 - mae: 1.5039 - val_loss: 18.1419 - val_mae: 2.6822\n",
      "Epoch 200/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.6660 - mae: 1.4564 - val_loss: 18.1532 - val_mae: 2.6982\n",
      "Epoch 201/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 4.6423 - mae: 1.4717 - val_loss: 18.0838 - val_mae: 2.6900\n",
      "Epoch 202/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.5785 - mae: 1.4528 - val_loss: 18.1211 - val_mae: 2.6888\n",
      "Epoch 203/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 4.6127 - mae: 1.4479 - val_loss: 17.9982 - val_mae: 2.6776\n",
      "Epoch 204/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.5839 - mae: 1.4359 - val_loss: 17.9644 - val_mae: 2.6846\n",
      "Epoch 205/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.6089 - mae: 1.4777 - val_loss: 17.9839 - val_mae: 2.6809\n",
      "Epoch 206/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 4.5641 - mae: 1.4525 - val_loss: 17.9995 - val_mae: 2.6581\n",
      "Epoch 207/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 4.6582 - mae: 1.4615 - val_loss: 18.0675 - val_mae: 2.7161\n",
      "Epoch 208/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.6869 - mae: 1.4628 - val_loss: 17.8264 - val_mae: 2.6433\n",
      "Epoch 209/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 4.5610 - mae: 1.4728 - val_loss: 18.2910 - val_mae: 2.7486\n",
      "Epoch 210/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.4384 - mae: 1.4324 - val_loss: 18.0411 - val_mae: 2.6600\n",
      "Epoch 211/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.5186 - mae: 1.4586 - val_loss: 18.0111 - val_mae: 2.6718\n",
      "Epoch 212/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 4.4220 - mae: 1.4352 - val_loss: 18.0902 - val_mae: 2.7199\n",
      "Epoch 213/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 4.4387 - mae: 1.4252 - val_loss: 17.8024 - val_mae: 2.6574\n",
      "Epoch 214/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.3994 - mae: 1.4257 - val_loss: 17.8650 - val_mae: 2.6750\n",
      "Epoch 215/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.4549 - mae: 1.4462 - val_loss: 17.9702 - val_mae: 2.6747\n",
      "Epoch 216/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.3840 - mae: 1.4003 - val_loss: 17.8520 - val_mae: 2.6692\n",
      "Epoch 217/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 4.3835 - mae: 1.4338 - val_loss: 17.8488 - val_mae: 2.6774\n",
      "Epoch 218/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 4.3959 - mae: 1.4372 - val_loss: 18.0361 - val_mae: 2.6804\n",
      "Epoch 219/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.3514 - mae: 1.3981 - val_loss: 18.1821 - val_mae: 2.6980\n",
      "Epoch 220/300\n",
      "269/269 [==============================] - 0s 134us/sample - loss: 4.3415 - mae: 1.4286 - val_loss: 18.0173 - val_mae: 2.6721\n",
      "Epoch 221/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.2465 - mae: 1.4136 - val_loss: 17.9375 - val_mae: 2.6809\n",
      "Epoch 222/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.3227 - mae: 1.3956 - val_loss: 17.8579 - val_mae: 2.6883\n",
      "Epoch 223/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.3666 - mae: 1.4546 - val_loss: 17.8947 - val_mae: 2.6731\n",
      "Epoch 224/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 4.3682 - mae: 1.3914 - val_loss: 18.0270 - val_mae: 2.6976\n",
      "Epoch 225/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.1773 - mae: 1.3846 - val_loss: 17.9347 - val_mae: 2.6787\n",
      "Epoch 226/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 4.2200 - mae: 1.4238 - val_loss: 18.0578 - val_mae: 2.6695\n",
      "Epoch 227/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 4.1572 - mae: 1.3836 - val_loss: 17.9531 - val_mae: 2.6781\n",
      "Epoch 228/300\n",
      "269/269 [==============================] - 0s 134us/sample - loss: 4.1268 - mae: 1.3700 - val_loss: 17.8819 - val_mae: 2.6693\n",
      "Epoch 229/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 4.1187 - mae: 1.3596 - val_loss: 17.8291 - val_mae: 2.6669\n",
      "Epoch 230/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 4.0898 - mae: 1.3654 - val_loss: 17.8953 - val_mae: 2.6750\n",
      "Epoch 231/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 4.1271 - mae: 1.3535 - val_loss: 17.9034 - val_mae: 2.6763\n",
      "Epoch 232/300\n",
      "269/269 [==============================] - 0s 135us/sample - loss: 4.0876 - mae: 1.3673 - val_loss: 17.8584 - val_mae: 2.6826\n",
      "Epoch 233/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 4.1199 - mae: 1.3978 - val_loss: 17.9369 - val_mae: 2.6844\n",
      "Epoch 234/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.1054 - mae: 1.3651 - val_loss: 17.8034 - val_mae: 2.6563\n",
      "Epoch 235/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 4.1188 - mae: 1.4042 - val_loss: 18.0235 - val_mae: 2.7077\n",
      "Epoch 236/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 4.0609 - mae: 1.3564 - val_loss: 18.0036 - val_mae: 2.6833\n",
      "Epoch 237/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.0680 - mae: 1.3502 - val_loss: 18.0419 - val_mae: 2.6862\n",
      "Epoch 238/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 4.0224 - mae: 1.3860 - val_loss: 17.8870 - val_mae: 2.6631\n",
      "Epoch 239/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 4.1277 - mae: 1.3713 - val_loss: 18.0050 - val_mae: 2.7061\n",
      "Epoch 240/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.9713 - mae: 1.3469 - val_loss: 18.0190 - val_mae: 2.6757\n",
      "Epoch 241/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 4.1048 - mae: 1.3801 - val_loss: 17.8926 - val_mae: 2.6721\n",
      "Epoch 242/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 3.9879 - mae: 1.3770 - val_loss: 17.9784 - val_mae: 2.7055\n",
      "Epoch 243/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 3.9720 - mae: 1.3385 - val_loss: 17.7796 - val_mae: 2.6568\n",
      "Epoch 244/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 4.0401 - mae: 1.3854 - val_loss: 17.9025 - val_mae: 2.6808\n",
      "Epoch 245/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 3.9460 - mae: 1.3495 - val_loss: 18.0230 - val_mae: 2.6929\n",
      "Epoch 246/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 4.0123 - mae: 1.3321 - val_loss: 17.8538 - val_mae: 2.6617\n",
      "Epoch 247/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 3.9064 - mae: 1.3654 - val_loss: 17.9314 - val_mae: 2.7019\n",
      "Epoch 248/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.8717 - mae: 1.3358 - val_loss: 17.8171 - val_mae: 2.6828\n",
      "Epoch 249/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.8629 - mae: 1.3437 - val_loss: 17.9281 - val_mae: 2.6834\n",
      "Epoch 250/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.9170 - mae: 1.3633 - val_loss: 17.9628 - val_mae: 2.7147\n",
      "Epoch 251/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 3.8240 - mae: 1.3222 - val_loss: 17.6686 - val_mae: 2.6585\n",
      "Epoch 252/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.7658 - mae: 1.3126 - val_loss: 17.7320 - val_mae: 2.6877\n",
      "Epoch 253/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 3.8550 - mae: 1.3397 - val_loss: 17.6960 - val_mae: 2.6570\n",
      "Epoch 254/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 3.8364 - mae: 1.3640 - val_loss: 17.8693 - val_mae: 2.7042\n",
      "Epoch 255/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.9361 - mae: 1.3620 - val_loss: 17.8685 - val_mae: 2.6849\n",
      "Epoch 256/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.7189 - mae: 1.3287 - val_loss: 17.9223 - val_mae: 2.7107\n",
      "Epoch 257/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.7600 - mae: 1.3340 - val_loss: 17.8977 - val_mae: 2.6770\n",
      "Epoch 258/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 3.6929 - mae: 1.2886 - val_loss: 17.8122 - val_mae: 2.6914\n",
      "Epoch 259/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.8510 - mae: 1.3645 - val_loss: 17.9941 - val_mae: 2.7027\n",
      "Epoch 260/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 137us/sample - loss: 3.7042 - mae: 1.3260 - val_loss: 17.8203 - val_mae: 2.6803\n",
      "Epoch 261/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 3.7878 - mae: 1.3248 - val_loss: 17.7302 - val_mae: 2.6943\n",
      "Epoch 262/300\n",
      "269/269 [==============================] - 0s 158us/sample - loss: 3.6249 - mae: 1.2872 - val_loss: 17.8237 - val_mae: 2.6886\n",
      "Epoch 263/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 3.6370 - mae: 1.2888 - val_loss: 17.9537 - val_mae: 2.6968\n",
      "Epoch 264/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.6051 - mae: 1.2978 - val_loss: 17.7600 - val_mae: 2.6917\n",
      "Epoch 265/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.6586 - mae: 1.3096 - val_loss: 17.7363 - val_mae: 2.6781\n",
      "Epoch 266/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.5546 - mae: 1.2891 - val_loss: 17.7228 - val_mae: 2.6830\n",
      "Epoch 267/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.5342 - mae: 1.2804 - val_loss: 17.7985 - val_mae: 2.6905\n",
      "Epoch 268/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.5654 - mae: 1.3092 - val_loss: 17.8519 - val_mae: 2.6935\n",
      "Epoch 269/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.7117 - mae: 1.2952 - val_loss: 17.7054 - val_mae: 2.6719\n",
      "Epoch 270/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 3.4841 - mae: 1.2780 - val_loss: 17.6689 - val_mae: 2.6816\n",
      "Epoch 271/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.5525 - mae: 1.2706 - val_loss: 17.5280 - val_mae: 2.6607\n",
      "Epoch 272/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.5735 - mae: 1.2953 - val_loss: 17.7107 - val_mae: 2.6821\n",
      "Epoch 273/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.5425 - mae: 1.2892 - val_loss: 17.7807 - val_mae: 2.6812\n",
      "Epoch 274/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 3.4838 - mae: 1.2838 - val_loss: 17.7335 - val_mae: 2.6962\n",
      "Epoch 275/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.4901 - mae: 1.2824 - val_loss: 17.6137 - val_mae: 2.6739\n",
      "Epoch 276/300\n",
      "269/269 [==============================] - 0s 145us/sample - loss: 3.4989 - mae: 1.2555 - val_loss: 17.6417 - val_mae: 2.6815\n",
      "Epoch 277/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.5332 - mae: 1.2888 - val_loss: 17.6482 - val_mae: 2.6767\n",
      "Epoch 278/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.4609 - mae: 1.2570 - val_loss: 17.8002 - val_mae: 2.7150\n",
      "Epoch 279/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.4871 - mae: 1.2908 - val_loss: 17.7075 - val_mae: 2.6813\n",
      "Epoch 280/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.3779 - mae: 1.2411 - val_loss: 17.5956 - val_mae: 2.6847\n",
      "Epoch 281/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.4884 - mae: 1.2632 - val_loss: 17.6193 - val_mae: 2.6848\n",
      "Epoch 282/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 3.3551 - mae: 1.2617 - val_loss: 17.6479 - val_mae: 2.6795\n",
      "Epoch 283/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.3672 - mae: 1.2405 - val_loss: 17.6254 - val_mae: 2.6869\n",
      "Epoch 284/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.3001 - mae: 1.2326 - val_loss: 17.4762 - val_mae: 2.6779\n",
      "Epoch 285/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.3345 - mae: 1.2481 - val_loss: 17.6990 - val_mae: 2.6941\n",
      "Epoch 286/300\n",
      "269/269 [==============================] - 0s 136us/sample - loss: 3.3118 - mae: 1.2306 - val_loss: 17.5032 - val_mae: 2.6778\n",
      "Epoch 287/300\n",
      "269/269 [==============================] - 0s 141us/sample - loss: 3.2998 - mae: 1.2249 - val_loss: 17.6477 - val_mae: 2.6881\n",
      "Epoch 288/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.2916 - mae: 1.2380 - val_loss: 17.7834 - val_mae: 2.6950\n",
      "Epoch 289/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 3.2602 - mae: 1.2236 - val_loss: 17.6286 - val_mae: 2.6795\n",
      "Epoch 290/300\n",
      "269/269 [==============================] - 0s 140us/sample - loss: 3.3072 - mae: 1.2331 - val_loss: 17.5320 - val_mae: 2.6798\n",
      "Epoch 291/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.2893 - mae: 1.2513 - val_loss: 17.6366 - val_mae: 2.6908\n",
      "Epoch 292/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.2701 - mae: 1.2317 - val_loss: 17.6619 - val_mae: 2.7053\n",
      "Epoch 293/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.2278 - mae: 1.2227 - val_loss: 17.5044 - val_mae: 2.6815\n",
      "Epoch 294/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.2324 - mae: 1.2163 - val_loss: 17.6938 - val_mae: 2.6988\n",
      "Epoch 295/300\n",
      "269/269 [==============================] - 0s 139us/sample - loss: 3.3488 - mae: 1.2580 - val_loss: 17.6072 - val_mae: 2.6871\n",
      "Epoch 296/300\n",
      "269/269 [==============================] - 0s 138us/sample - loss: 3.2572 - mae: 1.2437 - val_loss: 17.6353 - val_mae: 2.6921\n",
      "Epoch 297/300\n",
      "269/269 [==============================] - 0s 137us/sample - loss: 3.1444 - mae: 1.2113 - val_loss: 17.4634 - val_mae: 2.6769\n",
      "Epoch 298/300\n",
      "269/269 [==============================] - 0s 142us/sample - loss: 3.1946 - mae: 1.2137 - val_loss: 17.5060 - val_mae: 2.6830\n",
      "Epoch 299/300\n",
      "269/269 [==============================] - 0s 148us/sample - loss: 3.1381 - mae: 1.2118 - val_loss: 17.5431 - val_mae: 2.6864\n",
      "Epoch 300/300\n",
      "269/269 [==============================] - 0s 143us/sample - loss: 3.1495 - mae: 1.1924 - val_loss: 17.5151 - val_mae: 2.6907\n",
      "102/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 67us/sample - loss: 4.6340 - mae: 1.9424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 134 samples\n",
      "Epoch 1/300\n",
      "270/270 [==============================] - 1s 2ms/sample - loss: 573.5076 - mae: 22.0592 - val_loss: 466.1482 - val_mae: 19.7233\n",
      "Epoch 2/300\n",
      "270/270 [==============================] - 0s 160us/sample - loss: 542.5716 - mae: 21.3439 - val_loss: 435.4961 - val_mae: 18.9335\n",
      "Epoch 3/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 504.7852 - mae: 20.4679 - val_loss: 398.3887 - val_mae: 17.9607\n",
      "Epoch 4/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 459.1794 - mae: 19.3764 - val_loss: 353.9593 - val_mae: 16.7408\n",
      "Epoch 5/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 403.8078 - mae: 18.0103 - val_loss: 302.8141 - val_mae: 15.2414\n",
      "Epoch 6/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 339.6616 - mae: 16.3383 - val_loss: 246.9471 - val_mae: 13.5610\n",
      "Epoch 7/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 272.4587 - mae: 14.3476 - val_loss: 188.7604 - val_mae: 11.6636\n",
      "Epoch 8/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 203.4751 - mae: 12.0856 - val_loss: 135.8086 - val_mae: 9.5991\n",
      "Epoch 9/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 144.4099 - mae: 9.6651 - val_loss: 93.2403 - val_mae: 7.7917\n",
      "Epoch 10/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 97.5250 - mae: 7.6470 - val_loss: 66.4306 - val_mae: 6.5897\n",
      "Epoch 11/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 70.0105 - mae: 6.3301 - val_loss: 52.2764 - val_mae: 5.7025\n",
      "Epoch 12/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 55.1426 - mae: 5.4532 - val_loss: 44.5476 - val_mae: 5.1365\n",
      "Epoch 13/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 46.5960 - mae: 4.8966 - val_loss: 37.8843 - val_mae: 4.7241\n",
      "Epoch 14/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 40.2577 - mae: 4.4931 - val_loss: 32.3620 - val_mae: 4.3897\n",
      "Epoch 15/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 34.9056 - mae: 4.1795 - val_loss: 28.3918 - val_mae: 4.1165\n",
      "Epoch 16/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 31.3777 - mae: 3.9571 - val_loss: 25.6348 - val_mae: 3.8900\n",
      "Epoch 17/300\n",
      "270/270 [==============================] - 0s 145us/sample - loss: 29.0152 - mae: 3.7698 - val_loss: 23.7985 - val_mae: 3.7433\n",
      "Epoch 18/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 27.3256 - mae: 3.6309 - val_loss: 22.3242 - val_mae: 3.6211\n",
      "Epoch 19/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 25.9318 - mae: 3.5234 - val_loss: 21.1612 - val_mae: 3.5187\n",
      "Epoch 20/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 24.7355 - mae: 3.4311 - val_loss: 20.3406 - val_mae: 3.4417\n",
      "Epoch 21/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 23.8473 - mae: 3.3691 - val_loss: 20.0054 - val_mae: 3.4362\n",
      "Epoch 22/300\n",
      "270/270 [==============================] - 0s 147us/sample - loss: 23.0396 - mae: 3.3238 - val_loss: 19.4689 - val_mae: 3.3913\n",
      "Epoch 23/300\n",
      "270/270 [==============================] - 0s 145us/sample - loss: 22.2696 - mae: 3.2656 - val_loss: 18.8901 - val_mae: 3.3267\n",
      "Epoch 24/300\n",
      "270/270 [==============================] - 0s 145us/sample - loss: 21.7561 - mae: 3.2242 - val_loss: 18.6376 - val_mae: 3.3041\n",
      "Epoch 25/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 21.1508 - mae: 3.1648 - val_loss: 18.0686 - val_mae: 3.2255\n",
      "Epoch 26/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 20.6327 - mae: 3.1057 - val_loss: 17.6484 - val_mae: 3.1764\n",
      "Epoch 27/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 20.0759 - mae: 3.0458 - val_loss: 17.2038 - val_mae: 3.1094\n",
      "Epoch 28/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 19.7300 - mae: 3.0046 - val_loss: 17.0329 - val_mae: 3.0943\n",
      "Epoch 29/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 19.1104 - mae: 2.9708 - val_loss: 16.8596 - val_mae: 3.0715\n",
      "Epoch 30/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 18.8658 - mae: 2.9464 - val_loss: 16.6217 - val_mae: 3.0328\n",
      "Epoch 31/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 18.4452 - mae: 2.9046 - val_loss: 16.5324 - val_mae: 3.0107\n",
      "Epoch 32/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 18.1854 - mae: 2.8838 - val_loss: 16.4759 - val_mae: 2.9994\n",
      "Epoch 33/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 17.7331 - mae: 2.8498 - val_loss: 16.3744 - val_mae: 2.9859\n",
      "Epoch 34/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 17.4497 - mae: 2.8224 - val_loss: 16.2063 - val_mae: 2.9559\n",
      "Epoch 35/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 17.1747 - mae: 2.7996 - val_loss: 16.2187 - val_mae: 2.9565\n",
      "Epoch 36/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 16.8410 - mae: 2.7744 - val_loss: 16.1451 - val_mae: 2.9386\n",
      "Epoch 37/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 16.6169 - mae: 2.7592 - val_loss: 16.1313 - val_mae: 2.9348\n",
      "Epoch 38/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 16.4147 - mae: 2.7641 - val_loss: 16.3832 - val_mae: 2.9734\n",
      "Epoch 39/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 16.1640 - mae: 2.7526 - val_loss: 16.2230 - val_mae: 2.9387\n",
      "Epoch 40/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 15.9612 - mae: 2.7208 - val_loss: 15.8717 - val_mae: 2.8901\n",
      "Epoch 41/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 15.7334 - mae: 2.6877 - val_loss: 15.7046 - val_mae: 2.8639\n",
      "Epoch 42/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 15.5292 - mae: 2.6697 - val_loss: 15.7164 - val_mae: 2.8690\n",
      "Epoch 43/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 15.3427 - mae: 2.6679 - val_loss: 15.8216 - val_mae: 2.8911\n",
      "Epoch 44/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 15.1292 - mae: 2.6503 - val_loss: 15.6816 - val_mae: 2.8658\n",
      "Epoch 45/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 14.9912 - mae: 2.6356 - val_loss: 15.6283 - val_mae: 2.8590\n",
      "Epoch 46/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 14.8328 - mae: 2.6201 - val_loss: 15.5220 - val_mae: 2.8533\n",
      "Epoch 47/300\n",
      "270/270 [==============================] - 0s 145us/sample - loss: 14.6768 - mae: 2.6151 - val_loss: 15.6011 - val_mae: 2.8666\n",
      "Epoch 48/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 14.5577 - mae: 2.6082 - val_loss: 15.4528 - val_mae: 2.8377\n",
      "Epoch 49/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 14.4312 - mae: 2.6169 - val_loss: 15.6283 - val_mae: 2.8797\n",
      "Epoch 50/300\n",
      "270/270 [==============================] - 0s 149us/sample - loss: 14.2658 - mae: 2.6196 - val_loss: 15.6808 - val_mae: 2.8882\n",
      "Epoch 51/300\n",
      "270/270 [==============================] - 0s 149us/sample - loss: 14.0480 - mae: 2.5901 - val_loss: 15.1516 - val_mae: 2.8231\n",
      "Epoch 52/300\n",
      "270/270 [==============================] - 0s 147us/sample - loss: 13.9386 - mae: 2.5634 - val_loss: 15.0476 - val_mae: 2.8051\n",
      "Epoch 53/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 13.8824 - mae: 2.5597 - val_loss: 15.0915 - val_mae: 2.8212\n",
      "Epoch 54/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 13.6605 - mae: 2.5464 - val_loss: 15.1450 - val_mae: 2.8347\n",
      "Epoch 55/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 13.5939 - mae: 2.5466 - val_loss: 15.1172 - val_mae: 2.8326\n",
      "Epoch 56/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 13.5006 - mae: 2.5312 - val_loss: 15.0793 - val_mae: 2.8311\n",
      "Epoch 57/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 13.3791 - mae: 2.5269 - val_loss: 15.1043 - val_mae: 2.8441\n",
      "Epoch 58/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 13.3625 - mae: 2.5365 - val_loss: 15.2100 - val_mae: 2.8478\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 139us/sample - loss: 13.1916 - mae: 2.5161 - val_loss: 15.0490 - val_mae: 2.8255\n",
      "Epoch 60/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 13.0382 - mae: 2.4976 - val_loss: 14.9491 - val_mae: 2.8045\n",
      "Epoch 61/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 12.9483 - mae: 2.4886 - val_loss: 14.9002 - val_mae: 2.8038\n",
      "Epoch 62/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 12.8699 - mae: 2.4828 - val_loss: 14.9592 - val_mae: 2.8133\n",
      "Epoch 63/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 12.7736 - mae: 2.4818 - val_loss: 14.9269 - val_mae: 2.8124\n",
      "Epoch 64/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 12.7206 - mae: 2.4752 - val_loss: 14.9588 - val_mae: 2.8029\n",
      "Epoch 65/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 12.5735 - mae: 2.4669 - val_loss: 15.0084 - val_mae: 2.8188\n",
      "Epoch 66/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 12.5098 - mae: 2.4670 - val_loss: 14.9868 - val_mae: 2.8215\n",
      "Epoch 67/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 12.4583 - mae: 2.4578 - val_loss: 14.9104 - val_mae: 2.8083\n",
      "Epoch 68/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 12.3323 - mae: 2.4391 - val_loss: 14.7017 - val_mae: 2.7864\n",
      "Epoch 69/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 12.2779 - mae: 2.4159 - val_loss: 14.4291 - val_mae: 2.7410\n",
      "Epoch 70/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 12.2324 - mae: 2.4214 - val_loss: 14.5199 - val_mae: 2.7589\n",
      "Epoch 71/300\n",
      "270/270 [==============================] - 0s 145us/sample - loss: 12.1200 - mae: 2.4128 - val_loss: 14.3908 - val_mae: 2.7407\n",
      "Epoch 72/300\n",
      "270/270 [==============================] - 0s 145us/sample - loss: 12.0694 - mae: 2.4241 - val_loss: 14.6476 - val_mae: 2.7902\n",
      "Epoch 73/300\n",
      "270/270 [==============================] - 0s 147us/sample - loss: 11.9625 - mae: 2.4209 - val_loss: 14.4669 - val_mae: 2.7573\n",
      "Epoch 74/300\n",
      "270/270 [==============================] - 0s 147us/sample - loss: 11.9352 - mae: 2.4040 - val_loss: 14.4581 - val_mae: 2.7615\n",
      "Epoch 75/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 11.8470 - mae: 2.4048 - val_loss: 14.5652 - val_mae: 2.7756\n",
      "Epoch 76/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 11.7437 - mae: 2.4032 - val_loss: 14.4635 - val_mae: 2.7558\n",
      "Epoch 77/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 11.7253 - mae: 2.3871 - val_loss: 14.1504 - val_mae: 2.7178\n",
      "Epoch 78/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 11.7053 - mae: 2.3986 - val_loss: 14.2402 - val_mae: 2.7567\n",
      "Epoch 79/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 11.5630 - mae: 2.3701 - val_loss: 14.1349 - val_mae: 2.7154\n",
      "Epoch 80/300\n",
      "270/270 [==============================] - 0s 146us/sample - loss: 11.5068 - mae: 2.3669 - val_loss: 14.4105 - val_mae: 2.7432\n",
      "Epoch 81/300\n",
      "270/270 [==============================] - 0s 146us/sample - loss: 11.4190 - mae: 2.3789 - val_loss: 14.7244 - val_mae: 2.7692\n",
      "Epoch 82/300\n",
      "270/270 [==============================] - 0s 145us/sample - loss: 11.3599 - mae: 2.3771 - val_loss: 14.7248 - val_mae: 2.7829\n",
      "Epoch 83/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 11.2850 - mae: 2.3638 - val_loss: 14.5537 - val_mae: 2.7586\n",
      "Epoch 84/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 11.2036 - mae: 2.3511 - val_loss: 14.5140 - val_mae: 2.7426\n",
      "Epoch 85/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 11.1729 - mae: 2.3589 - val_loss: 14.5794 - val_mae: 2.7648\n",
      "Epoch 86/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 11.1309 - mae: 2.3548 - val_loss: 14.3951 - val_mae: 2.7310\n",
      "Epoch 87/300\n",
      "270/270 [==============================] - 0s 146us/sample - loss: 11.0865 - mae: 2.3528 - val_loss: 14.4669 - val_mae: 2.7580\n",
      "Epoch 88/300\n",
      "270/270 [==============================] - 0s 149us/sample - loss: 11.0122 - mae: 2.3510 - val_loss: 14.2458 - val_mae: 2.7389\n",
      "Epoch 89/300\n",
      "270/270 [==============================] - 0s 150us/sample - loss: 10.9748 - mae: 2.3372 - val_loss: 14.0273 - val_mae: 2.7157\n",
      "Epoch 90/300\n",
      "270/270 [==============================] - 0s 147us/sample - loss: 10.8727 - mae: 2.3315 - val_loss: 14.1316 - val_mae: 2.7274\n",
      "Epoch 91/300\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 10.8686 - mae: 2.3416 - val_loss: 14.3817 - val_mae: 2.7377\n",
      "Epoch 92/300\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 10.7548 - mae: 2.3232 - val_loss: 14.1318 - val_mae: 2.7198\n",
      "Epoch 93/300\n",
      "270/270 [==============================] - 0s 150us/sample - loss: 10.7151 - mae: 2.3071 - val_loss: 14.1330 - val_mae: 2.7061\n",
      "Epoch 94/300\n",
      "270/270 [==============================] - 0s 145us/sample - loss: 10.6796 - mae: 2.3177 - val_loss: 14.2918 - val_mae: 2.7462\n",
      "Epoch 95/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 10.6148 - mae: 2.3206 - val_loss: 14.2522 - val_mae: 2.7379\n",
      "Epoch 96/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 10.6097 - mae: 2.2965 - val_loss: 13.8713 - val_mae: 2.6874\n",
      "Epoch 97/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 10.5295 - mae: 2.2906 - val_loss: 14.0888 - val_mae: 2.7027\n",
      "Epoch 98/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 10.4905 - mae: 2.2959 - val_loss: 14.1267 - val_mae: 2.7079\n",
      "Epoch 99/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 10.4882 - mae: 2.3031 - val_loss: 13.9417 - val_mae: 2.7123\n",
      "Epoch 100/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 10.4949 - mae: 2.2928 - val_loss: 14.2840 - val_mae: 2.7220\n",
      "Epoch 101/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 10.3548 - mae: 2.2790 - val_loss: 14.0005 - val_mae: 2.7075\n",
      "Epoch 102/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 10.2261 - mae: 2.2780 - val_loss: 14.2252 - val_mae: 2.7438\n",
      "Epoch 103/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 10.2905 - mae: 2.2947 - val_loss: 14.2329 - val_mae: 2.7295\n",
      "Epoch 104/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 10.1577 - mae: 2.2675 - val_loss: 13.9051 - val_mae: 2.7082\n",
      "Epoch 105/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 10.1599 - mae: 2.2512 - val_loss: 13.7298 - val_mae: 2.7013\n",
      "Epoch 106/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 10.0597 - mae: 2.2372 - val_loss: 13.8812 - val_mae: 2.7070\n",
      "Epoch 107/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 10.0076 - mae: 2.2394 - val_loss: 13.8836 - val_mae: 2.6944\n",
      "Epoch 108/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 10.0515 - mae: 2.2443 - val_loss: 13.9173 - val_mae: 2.6984\n",
      "Epoch 109/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 9.9509 - mae: 2.2429 - val_loss: 14.0542 - val_mae: 2.7209\n",
      "Epoch 110/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 10.0033 - mae: 2.2678 - val_loss: 13.8827 - val_mae: 2.7225\n",
      "Epoch 111/300\n",
      "270/270 [==============================] - 0s 149us/sample - loss: 9.9764 - mae: 2.2386 - val_loss: 13.4993 - val_mae: 2.6595\n",
      "Epoch 112/300\n",
      "270/270 [==============================] - 0s 145us/sample - loss: 9.8856 - mae: 2.2146 - val_loss: 13.6349 - val_mae: 2.6587\n",
      "Epoch 113/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 9.8378 - mae: 2.2143 - val_loss: 13.6214 - val_mae: 2.6955\n",
      "Epoch 114/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 9.7719 - mae: 2.2277 - val_loss: 13.6900 - val_mae: 2.6880\n",
      "Epoch 115/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 9.6673 - mae: 2.2136 - val_loss: 13.7327 - val_mae: 2.6874\n",
      "Epoch 116/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 9.6982 - mae: 2.2095 - val_loss: 13.5730 - val_mae: 2.6723\n",
      "Epoch 117/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 9.6616 - mae: 2.2201 - val_loss: 14.0054 - val_mae: 2.7113\n",
      "Epoch 118/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 9.6742 - mae: 2.2339 - val_loss: 14.0830 - val_mae: 2.7332\n",
      "Epoch 119/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 9.5338 - mae: 2.2038 - val_loss: 13.4405 - val_mae: 2.6723\n",
      "Epoch 120/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 9.6223 - mae: 2.1909 - val_loss: 13.3542 - val_mae: 2.6520\n",
      "Epoch 121/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 9.4188 - mae: 2.1739 - val_loss: 13.7674 - val_mae: 2.6937\n",
      "Epoch 122/300\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 9.4984 - mae: 2.2011 - val_loss: 13.7233 - val_mae: 2.6983\n",
      "Epoch 123/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 9.5771 - mae: 2.2278 - val_loss: 14.2004 - val_mae: 2.7166\n",
      "Epoch 124/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 9.3487 - mae: 2.1929 - val_loss: 13.5887 - val_mae: 2.7020\n",
      "Epoch 125/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 9.3591 - mae: 2.1790 - val_loss: 13.3265 - val_mae: 2.6499\n",
      "Epoch 126/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 9.2782 - mae: 2.1723 - val_loss: 13.7913 - val_mae: 2.6898\n",
      "Epoch 127/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 9.2272 - mae: 2.1784 - val_loss: 13.5832 - val_mae: 2.6808\n",
      "Epoch 128/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 9.1648 - mae: 2.1717 - val_loss: 13.8352 - val_mae: 2.6952\n",
      "Epoch 129/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 9.1183 - mae: 2.1678 - val_loss: 13.6700 - val_mae: 2.6846\n",
      "Epoch 130/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 9.1045 - mae: 2.1713 - val_loss: 13.7113 - val_mae: 2.6911\n",
      "Epoch 131/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 9.0141 - mae: 2.1636 - val_loss: 13.4023 - val_mae: 2.6639\n",
      "Epoch 132/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 8.9622 - mae: 2.1470 - val_loss: 13.2953 - val_mae: 2.6590\n",
      "Epoch 133/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 8.9845 - mae: 2.1297 - val_loss: 13.1929 - val_mae: 2.6297\n",
      "Epoch 134/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 8.9634 - mae: 2.1506 - val_loss: 13.4595 - val_mae: 2.6686\n",
      "Epoch 135/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 8.8718 - mae: 2.1392 - val_loss: 13.4578 - val_mae: 2.6656\n",
      "Epoch 136/300\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 8.8233 - mae: 2.1299 - val_loss: 13.2704 - val_mae: 2.6415\n",
      "Epoch 137/300\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 8.7664 - mae: 2.1173 - val_loss: 13.1981 - val_mae: 2.6288\n",
      "Epoch 138/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 8.8042 - mae: 2.1215 - val_loss: 13.1262 - val_mae: 2.6380\n",
      "Epoch 139/300\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 8.6847 - mae: 2.1160 - val_loss: 13.3084 - val_mae: 2.6438\n",
      "Epoch 140/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 8.8314 - mae: 2.1483 - val_loss: 13.9794 - val_mae: 2.7183\n",
      "Epoch 141/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 8.7014 - mae: 2.1204 - val_loss: 13.0133 - val_mae: 2.6123\n",
      "Epoch 142/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 8.6219 - mae: 2.1023 - val_loss: 12.9401 - val_mae: 2.6112\n",
      "Epoch 143/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 8.6394 - mae: 2.1150 - val_loss: 13.3417 - val_mae: 2.6477\n",
      "Epoch 144/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 8.5287 - mae: 2.1020 - val_loss: 13.2876 - val_mae: 2.6279\n",
      "Epoch 145/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 8.4756 - mae: 2.0946 - val_loss: 13.0763 - val_mae: 2.6231\n",
      "Epoch 146/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 8.4409 - mae: 2.0882 - val_loss: 12.9612 - val_mae: 2.6172\n",
      "Epoch 147/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 8.4394 - mae: 2.0907 - val_loss: 12.9236 - val_mae: 2.6127\n",
      "Epoch 148/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 8.3625 - mae: 2.0733 - val_loss: 13.2841 - val_mae: 2.6355\n",
      "Epoch 149/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 8.3132 - mae: 2.0775 - val_loss: 13.1123 - val_mae: 2.6183\n",
      "Epoch 150/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 8.2571 - mae: 2.0683 - val_loss: 13.0699 - val_mae: 2.6207\n",
      "Epoch 151/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 8.2510 - mae: 2.0749 - val_loss: 13.1335 - val_mae: 2.6319\n",
      "Epoch 152/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 8.2834 - mae: 2.0803 - val_loss: 12.9371 - val_mae: 2.5911\n",
      "Epoch 153/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 8.1541 - mae: 2.0550 - val_loss: 12.9154 - val_mae: 2.6180\n",
      "Epoch 154/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 8.1753 - mae: 2.0813 - val_loss: 13.0550 - val_mae: 2.6266\n",
      "Epoch 155/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 8.0453 - mae: 2.0508 - val_loss: 12.7701 - val_mae: 2.5867\n",
      "Epoch 156/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 8.0533 - mae: 2.0491 - val_loss: 12.6867 - val_mae: 2.5889\n",
      "Epoch 157/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 7.9735 - mae: 2.0384 - val_loss: 12.7537 - val_mae: 2.6032\n",
      "Epoch 158/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 7.9363 - mae: 2.0376 - val_loss: 12.8577 - val_mae: 2.6073\n",
      "Epoch 159/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 7.9241 - mae: 2.0444 - val_loss: 13.1675 - val_mae: 2.6436\n",
      "Epoch 160/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 7.8958 - mae: 2.0388 - val_loss: 13.0013 - val_mae: 2.6091\n",
      "Epoch 161/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 7.8551 - mae: 2.0251 - val_loss: 12.8365 - val_mae: 2.6030\n",
      "Epoch 162/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 7.8215 - mae: 2.0236 - val_loss: 12.6470 - val_mae: 2.5904\n",
      "Epoch 163/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 7.7722 - mae: 2.0178 - val_loss: 12.8077 - val_mae: 2.6032\n",
      "Epoch 164/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 7.8374 - mae: 2.0468 - val_loss: 13.2788 - val_mae: 2.6341\n",
      "Epoch 165/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 7.7108 - mae: 2.0181 - val_loss: 12.8016 - val_mae: 2.6192\n",
      "Epoch 166/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 7.7517 - mae: 2.0279 - val_loss: 12.8401 - val_mae: 2.6207\n",
      "Epoch 167/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 7.6151 - mae: 2.0076 - val_loss: 13.0585 - val_mae: 2.6092\n",
      "Epoch 168/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 7.6244 - mae: 2.0164 - val_loss: 13.4531 - val_mae: 2.6486\n",
      "Epoch 169/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 7.5727 - mae: 2.0066 - val_loss: 12.7999 - val_mae: 2.5966\n",
      "Epoch 170/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 7.5648 - mae: 1.9954 - val_loss: 12.6018 - val_mae: 2.5834\n",
      "Epoch 171/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 7.5170 - mae: 1.9961 - val_loss: 12.9858 - val_mae: 2.5979\n",
      "Epoch 172/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 7.5880 - mae: 1.9849 - val_loss: 12.4088 - val_mae: 2.5691\n",
      "Epoch 173/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 7.3637 - mae: 1.9728 - val_loss: 12.8410 - val_mae: 2.6036\n",
      "Epoch 174/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 7.4470 - mae: 1.9896 - val_loss: 12.9390 - val_mae: 2.6116\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 141us/sample - loss: 7.3155 - mae: 1.9684 - val_loss: 12.5500 - val_mae: 2.5701\n",
      "Epoch 176/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 7.3284 - mae: 1.9686 - val_loss: 12.5628 - val_mae: 2.5857\n",
      "Epoch 177/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 7.3697 - mae: 1.9822 - val_loss: 12.8553 - val_mae: 2.5900\n",
      "Epoch 178/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 7.2101 - mae: 1.9502 - val_loss: 12.3705 - val_mae: 2.5728\n",
      "Epoch 179/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 7.2130 - mae: 1.9426 - val_loss: 12.5471 - val_mae: 2.5745\n",
      "Epoch 180/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 7.2259 - mae: 1.9591 - val_loss: 12.8003 - val_mae: 2.5906\n",
      "Epoch 181/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 7.2126 - mae: 1.9697 - val_loss: 12.6343 - val_mae: 2.6149\n",
      "Epoch 182/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 7.0687 - mae: 1.9320 - val_loss: 12.4069 - val_mae: 2.5501\n",
      "Epoch 183/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 7.0641 - mae: 1.9283 - val_loss: 12.4116 - val_mae: 2.5710\n",
      "Epoch 184/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 6.9627 - mae: 1.9244 - val_loss: 12.7760 - val_mae: 2.5962\n",
      "Epoch 185/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 6.9868 - mae: 1.9355 - val_loss: 12.7045 - val_mae: 2.5837\n",
      "Epoch 186/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 6.8806 - mae: 1.9050 - val_loss: 12.3027 - val_mae: 2.5528\n",
      "Epoch 187/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 6.8604 - mae: 1.9087 - val_loss: 12.5719 - val_mae: 2.5677\n",
      "Epoch 188/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 6.8096 - mae: 1.9166 - val_loss: 12.6929 - val_mae: 2.5935\n",
      "Epoch 189/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 6.8074 - mae: 1.9173 - val_loss: 12.3572 - val_mae: 2.5539\n",
      "Epoch 190/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 6.7303 - mae: 1.8973 - val_loss: 12.2846 - val_mae: 2.5550\n",
      "Epoch 191/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 6.6763 - mae: 1.8892 - val_loss: 12.5130 - val_mae: 2.5639\n",
      "Epoch 192/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 6.6584 - mae: 1.8886 - val_loss: 12.6548 - val_mae: 2.5689\n",
      "Epoch 193/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 6.5870 - mae: 1.8771 - val_loss: 12.2788 - val_mae: 2.5465\n",
      "Epoch 194/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 6.6073 - mae: 1.8657 - val_loss: 12.0679 - val_mae: 2.5279\n",
      "Epoch 195/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 6.5620 - mae: 1.8687 - val_loss: 12.2719 - val_mae: 2.5394\n",
      "Epoch 196/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 6.5678 - mae: 1.8728 - val_loss: 12.5541 - val_mae: 2.5884\n",
      "Epoch 197/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 6.5318 - mae: 1.8743 - val_loss: 12.2624 - val_mae: 2.5287\n",
      "Epoch 198/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 6.4404 - mae: 1.8481 - val_loss: 12.4257 - val_mae: 2.5602\n",
      "Epoch 199/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 6.5188 - mae: 1.8427 - val_loss: 11.9025 - val_mae: 2.5024\n",
      "Epoch 200/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 6.4291 - mae: 1.8417 - val_loss: 12.4671 - val_mae: 2.5523\n",
      "Epoch 201/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 6.3211 - mae: 1.8235 - val_loss: 12.1655 - val_mae: 2.5526\n",
      "Epoch 202/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 6.2983 - mae: 1.8219 - val_loss: 12.4701 - val_mae: 2.5516\n",
      "Epoch 203/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 6.2629 - mae: 1.8234 - val_loss: 12.1192 - val_mae: 2.5263\n",
      "Epoch 204/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 6.1554 - mae: 1.8164 - val_loss: 12.7988 - val_mae: 2.5878\n",
      "Epoch 205/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 6.1569 - mae: 1.8164 - val_loss: 12.3106 - val_mae: 2.5339\n",
      "Epoch 206/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 6.1629 - mae: 1.7968 - val_loss: 11.9824 - val_mae: 2.5331\n",
      "Epoch 207/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 6.1648 - mae: 1.8165 - val_loss: 12.6129 - val_mae: 2.5622\n",
      "Epoch 208/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 6.0267 - mae: 1.7921 - val_loss: 12.2558 - val_mae: 2.5430\n",
      "Epoch 209/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 6.0294 - mae: 1.7745 - val_loss: 11.9311 - val_mae: 2.5188\n",
      "Epoch 210/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 6.0172 - mae: 1.7807 - val_loss: 12.3350 - val_mae: 2.5468\n",
      "Epoch 211/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 6.0427 - mae: 1.8064 - val_loss: 12.5894 - val_mae: 2.5883\n",
      "Epoch 212/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 5.8857 - mae: 1.7762 - val_loss: 11.9281 - val_mae: 2.5042\n",
      "Epoch 213/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 5.9581 - mae: 1.7610 - val_loss: 12.0654 - val_mae: 2.5385\n",
      "Epoch 214/300\n",
      "270/270 [==============================] - 0s 145us/sample - loss: 5.7816 - mae: 1.7442 - val_loss: 12.0726 - val_mae: 2.5134\n",
      "Epoch 215/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 5.7534 - mae: 1.7460 - val_loss: 12.0786 - val_mae: 2.5327\n",
      "Epoch 216/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 5.7621 - mae: 1.7622 - val_loss: 12.4220 - val_mae: 2.5558\n",
      "Epoch 217/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 5.7034 - mae: 1.7458 - val_loss: 12.0166 - val_mae: 2.5099\n",
      "Epoch 218/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 5.8065 - mae: 1.7390 - val_loss: 11.8567 - val_mae: 2.4884\n",
      "Epoch 219/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 5.6358 - mae: 1.7211 - val_loss: 12.3847 - val_mae: 2.5594\n",
      "Epoch 220/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 5.6633 - mae: 1.7451 - val_loss: 12.1979 - val_mae: 2.5358\n",
      "Epoch 221/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 5.6056 - mae: 1.7248 - val_loss: 12.0240 - val_mae: 2.5146\n",
      "Epoch 222/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 5.5374 - mae: 1.6983 - val_loss: 11.8623 - val_mae: 2.4966\n",
      "Epoch 223/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 5.4909 - mae: 1.6975 - val_loss: 12.1004 - val_mae: 2.5048\n",
      "Epoch 224/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 5.4773 - mae: 1.7045 - val_loss: 12.2258 - val_mae: 2.5138\n",
      "Epoch 225/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 5.4833 - mae: 1.6984 - val_loss: 11.6844 - val_mae: 2.4903\n",
      "Epoch 226/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 5.5185 - mae: 1.7122 - val_loss: 12.0745 - val_mae: 2.5035\n",
      "Epoch 227/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 5.3849 - mae: 1.6933 - val_loss: 11.9268 - val_mae: 2.5111\n",
      "Epoch 228/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 5.3576 - mae: 1.6867 - val_loss: 12.1098 - val_mae: 2.5108\n",
      "Epoch 229/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 5.3877 - mae: 1.6836 - val_loss: 11.7739 - val_mae: 2.4779\n",
      "Epoch 230/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 5.3483 - mae: 1.6796 - val_loss: 12.2147 - val_mae: 2.5311\n",
      "Epoch 231/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 5.2647 - mae: 1.6735 - val_loss: 11.7636 - val_mae: 2.4822\n",
      "Epoch 232/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 5.2512 - mae: 1.6524 - val_loss: 11.8483 - val_mae: 2.4909\n",
      "Epoch 233/300\n",
      "270/270 [==============================] - 0s 146us/sample - loss: 5.2070 - mae: 1.6647 - val_loss: 12.0601 - val_mae: 2.5109\n",
      "Epoch 234/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 5.1752 - mae: 1.6497 - val_loss: 11.7474 - val_mae: 2.4582\n",
      "Epoch 235/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 5.1820 - mae: 1.6546 - val_loss: 11.7775 - val_mae: 2.4795\n",
      "Epoch 236/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 5.1265 - mae: 1.6404 - val_loss: 11.9324 - val_mae: 2.4940\n",
      "Epoch 237/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 5.1068 - mae: 1.6426 - val_loss: 11.8314 - val_mae: 2.4992\n",
      "Epoch 238/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 5.1197 - mae: 1.6523 - val_loss: 11.8359 - val_mae: 2.4835\n",
      "Epoch 239/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 5.0660 - mae: 1.6409 - val_loss: 11.7642 - val_mae: 2.4785\n",
      "Epoch 240/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 5.0174 - mae: 1.6185 - val_loss: 11.8695 - val_mae: 2.4688\n",
      "Epoch 241/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 4.9854 - mae: 1.6295 - val_loss: 11.8613 - val_mae: 2.4849\n",
      "Epoch 242/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 4.9372 - mae: 1.6168 - val_loss: 11.6903 - val_mae: 2.4622\n",
      "Epoch 243/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 4.9788 - mae: 1.6048 - val_loss: 11.6861 - val_mae: 2.4533\n",
      "Epoch 244/300\n",
      "270/270 [==============================] - 0s 145us/sample - loss: 4.9886 - mae: 1.6240 - val_loss: 12.2568 - val_mae: 2.5126\n",
      "Epoch 245/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 4.8857 - mae: 1.6095 - val_loss: 11.7913 - val_mae: 2.4683\n",
      "Epoch 246/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 4.8229 - mae: 1.5947 - val_loss: 11.8437 - val_mae: 2.4750\n",
      "Epoch 247/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 4.8653 - mae: 1.6097 - val_loss: 11.8061 - val_mae: 2.4659\n",
      "Epoch 248/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 4.7568 - mae: 1.5822 - val_loss: 11.6303 - val_mae: 2.4502\n",
      "Epoch 249/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 4.8359 - mae: 1.5829 - val_loss: 11.5337 - val_mae: 2.4388\n",
      "Epoch 250/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 4.7458 - mae: 1.5741 - val_loss: 11.9861 - val_mae: 2.4812\n",
      "Epoch 251/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 4.7468 - mae: 1.5801 - val_loss: 11.7180 - val_mae: 2.4656\n",
      "Epoch 252/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 4.6677 - mae: 1.5698 - val_loss: 12.1211 - val_mae: 2.5028\n",
      "Epoch 253/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 4.7957 - mae: 1.5989 - val_loss: 11.7960 - val_mae: 2.4709\n",
      "Epoch 254/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 4.6448 - mae: 1.5497 - val_loss: 11.7480 - val_mae: 2.4632\n",
      "Epoch 255/300\n",
      "270/270 [==============================] - 0s 145us/sample - loss: 4.6246 - mae: 1.5558 - val_loss: 11.8767 - val_mae: 2.4840\n",
      "Epoch 256/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 4.7760 - mae: 1.5952 - val_loss: 11.8495 - val_mae: 2.4714\n",
      "Epoch 257/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 4.5837 - mae: 1.5626 - val_loss: 11.8399 - val_mae: 2.4834\n",
      "Epoch 258/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 4.5546 - mae: 1.5581 - val_loss: 11.6136 - val_mae: 2.4525\n",
      "Epoch 259/300\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 4.5813 - mae: 1.5455 - val_loss: 11.7052 - val_mae: 2.4611\n",
      "Epoch 260/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 4.5088 - mae: 1.5388 - val_loss: 11.8653 - val_mae: 2.4766\n",
      "Epoch 261/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 4.5176 - mae: 1.5430 - val_loss: 11.8938 - val_mae: 2.4796\n",
      "Epoch 262/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 4.5307 - mae: 1.5431 - val_loss: 11.8197 - val_mae: 2.4669\n",
      "Epoch 263/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 4.4323 - mae: 1.5149 - val_loss: 11.5704 - val_mae: 2.4568\n",
      "Epoch 264/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 4.4340 - mae: 1.5245 - val_loss: 11.8826 - val_mae: 2.4766\n",
      "Epoch 265/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 4.4325 - mae: 1.5221 - val_loss: 11.8551 - val_mae: 2.4616\n",
      "Epoch 266/300\n",
      "270/270 [==============================] - 0s 147us/sample - loss: 4.4432 - mae: 1.5296 - val_loss: 12.1241 - val_mae: 2.4991\n",
      "Epoch 267/300\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 4.3871 - mae: 1.5272 - val_loss: 11.7286 - val_mae: 2.4661\n",
      "Epoch 268/300\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 4.3324 - mae: 1.5014 - val_loss: 11.7476 - val_mae: 2.4659\n",
      "Epoch 269/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 4.3740 - mae: 1.5270 - val_loss: 12.0646 - val_mae: 2.5092\n",
      "Epoch 270/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 4.2925 - mae: 1.4995 - val_loss: 12.0383 - val_mae: 2.4912\n",
      "Epoch 271/300\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 4.3026 - mae: 1.4969 - val_loss: 11.7497 - val_mae: 2.4505\n",
      "Epoch 272/300\n",
      "270/270 [==============================] - 0s 135us/sample - loss: 4.2970 - mae: 1.4911 - val_loss: 11.9314 - val_mae: 2.4764\n",
      "Epoch 273/300\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 4.2792 - mae: 1.5046 - val_loss: 12.2494 - val_mae: 2.5034\n",
      "Epoch 274/300\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 4.2422 - mae: 1.4856 - val_loss: 11.9820 - val_mae: 2.4807\n",
      "Epoch 275/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 4.2301 - mae: 1.4849 - val_loss: 11.9739 - val_mae: 2.4726\n",
      "Epoch 276/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 4.2063 - mae: 1.4948 - val_loss: 12.0247 - val_mae: 2.4894\n",
      "Epoch 277/300\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 4.2254 - mae: 1.4801 - val_loss: 12.0633 - val_mae: 2.4958\n",
      "Epoch 278/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 4.1842 - mae: 1.4781 - val_loss: 12.0370 - val_mae: 2.4864\n",
      "Epoch 279/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 4.1258 - mae: 1.4689 - val_loss: 11.9494 - val_mae: 2.4705\n",
      "Epoch 280/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 4.2281 - mae: 1.4807 - val_loss: 12.1393 - val_mae: 2.4863\n",
      "Epoch 281/300\n",
      "270/270 [==============================] - 0s 136us/sample - loss: 4.1587 - mae: 1.4746 - val_loss: 11.8908 - val_mae: 2.4745\n",
      "Epoch 282/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 4.0915 - mae: 1.4524 - val_loss: 12.0979 - val_mae: 2.4835\n",
      "Epoch 283/300\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 4.0783 - mae: 1.4416 - val_loss: 12.0120 - val_mae: 2.4820\n",
      "Epoch 284/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 4.0725 - mae: 1.4608 - val_loss: 12.3565 - val_mae: 2.5179\n",
      "Epoch 285/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 4.0424 - mae: 1.4443 - val_loss: 11.8323 - val_mae: 2.4538\n",
      "Epoch 286/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 4.0553 - mae: 1.4397 - val_loss: 12.3616 - val_mae: 2.5277\n",
      "Epoch 287/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 4.0142 - mae: 1.4405 - val_loss: 12.1397 - val_mae: 2.5089\n",
      "Epoch 288/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 4.0570 - mae: 1.4554 - val_loss: 12.5505 - val_mae: 2.5441\n",
      "Epoch 289/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 4.0349 - mae: 1.4713 - val_loss: 12.2899 - val_mae: 2.5188\n",
      "Epoch 290/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 4.0408 - mae: 1.4380 - val_loss: 12.0826 - val_mae: 2.4842\n",
      "Epoch 291/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 139us/sample - loss: 4.1164 - mae: 1.4614 - val_loss: 12.5573 - val_mae: 2.5403\n",
      "Epoch 292/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 3.9387 - mae: 1.4273 - val_loss: 12.0694 - val_mae: 2.4796\n",
      "Epoch 293/300\n",
      "270/270 [==============================] - 0s 141us/sample - loss: 3.9989 - mae: 1.4209 - val_loss: 12.4758 - val_mae: 2.5201\n",
      "Epoch 294/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 3.9512 - mae: 1.4412 - val_loss: 12.4607 - val_mae: 2.5242\n",
      "Epoch 295/300\n",
      "270/270 [==============================] - 0s 142us/sample - loss: 3.8738 - mae: 1.4086 - val_loss: 12.2398 - val_mae: 2.4951\n",
      "Epoch 296/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 3.8746 - mae: 1.4179 - val_loss: 12.2000 - val_mae: 2.4951\n",
      "Epoch 297/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 3.8053 - mae: 1.3984 - val_loss: 12.4494 - val_mae: 2.5189\n",
      "Epoch 298/300\n",
      "270/270 [==============================] - 0s 139us/sample - loss: 3.8258 - mae: 1.3887 - val_loss: 12.2268 - val_mae: 2.4979\n",
      "Epoch 299/300\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 3.8626 - mae: 1.4208 - val_loss: 12.7711 - val_mae: 2.5710\n",
      "Epoch 300/300\n",
      "270/270 [==============================] - 0s 138us/sample - loss: 3.7947 - mae: 1.4119 - val_loss: 12.3156 - val_mae: 2.5139\n",
      "102/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 69us/sample - loss: 6.0135 - mae: 2.1546\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "    path='boston_housing.npz',\n",
    "    test_split=0.2,\n",
    "    seed=777\n",
    ")\n",
    "\n",
    "# 데이터 표준화\n",
    "mean = np.mean(x_train, axis = 0)\n",
    "std = np.std(x_train, axis = 0)\n",
    "# 여기까진 전부 동일합니다.\n",
    "x_train = (x_train - mean) / std\n",
    "x_test = (x_test - mean) / std\n",
    "\n",
    "# K-Fold를 진행해봅니다.\n",
    "k = 3\n",
    "\n",
    "# 주어진 데이터셋을 k만큼 등분합니다.\n",
    "# 여기서는 3이므로 훈련 데이터셋(404개)를 3등분하여\n",
    "# 1개는 검증셋으로, 나머지 2개는 훈련셋으로 활용합니다.\n",
    "kfold = KFold(n_splits=k, random_state = 777)\n",
    "\n",
    "# 재사용을 위해 모델을 반환하는 함수를 정의합니다.\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation = 'relu', input_shape = (13, )))\n",
    "    model.add(Dense(32, activation = 'relu')) \n",
    "    model.add(Dense(1))   \n",
    "\n",
    "    model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "mae_list = [] # 테스트셋을 평가한 후 결과 mae를 담을 리스트를 선언합니다.\n",
    "\n",
    "# k번 진행합니다.\n",
    "for train_index, val_index in kfold.split(x_train):\n",
    "    # 해당 인덱스는 무작위로 생성됩니다.\n",
    "    # 무작위로 생성해주는 것은 과대적합을 피할 수 있는 좋은 방법입니다.\n",
    "    x_train_fold, x_val_fold = x_train[train_index], x_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    # 모델을 불러옵니다.\n",
    "    model = get_model()\n",
    "    \n",
    "    model.fit(x_train_fold, y_train_fold, epochs = 300, validation_data = (x_val_fold, y_val_fold))\n",
    "    \n",
    "    _, test_mae = model.evaluate(x_test, y_test)\n",
    "    mae_list.append(test_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.057369, 1.9423964, 2.1546433]\n"
     ]
    }
   ],
   "source": [
    "print(mae_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0514696\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(mae_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_study",
   "language": "python",
   "name": "keras_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
